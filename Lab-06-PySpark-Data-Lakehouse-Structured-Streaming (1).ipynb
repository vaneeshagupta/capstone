{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8476b62d-2825-400c-be4c-35bb3aa81b1c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Lab 6: Building a Data Lakehouse with the PySpark Structured Streaming Medallion Architecture\n",
    "This lab will help you learn to use many of the software libraries and programming techniques required to fulfill the requirements of the final end-of-session capstone project for course **DS-2002: Data Systems**. The spirit of the project is to provide a capstone challenge that requires students to demonstrate a practical and functional understanding of each of the data systems and architectural principles covered throughout the session.\n",
    "\n",
    "**These include:**\n",
    "- Relational Database Management Systems (e.g., MySQL, Microsoft SQL Server, Oracle, IBM DB2)\n",
    "  - Online Transaction Processing Systems (OLTP): *Optimized for High-Volume Write Operations; Normalized to 3rd Normal Form.*\n",
    "  - Online Analytical Processing Systems (OLAP): *Optimized for Read/Aggregation Operations; Dimensional Model (i.e, Star Schema)*\n",
    "- NoSQL *(Not Only SQL)* Systems (e.g., MongoDB, CosmosDB, Cassandra, HBase, Redis)\n",
    "- File System *(Data Lake)* Source Systems (e.g., AWS S3, Microsoft Azure Data Lake Storage)\n",
    "  - Various Datafile Formats (e.g., JSON, CSV, Parquet, Text, Binary)\n",
    "- Massively Parallel Processing *(MPP)* Data Integration Systems (e.g., Apache Spark/PySpark, Databricks)\n",
    "- Data Integration Patterns (e.g., Extract-Transform-Load, Extract-Load-Transform, Extract-Load-Transform-Load, Lambda & Kappa Architectures)\n",
    "\n",
    "## Section I: Prerequisites\n",
    "\n",
    "### 1.0. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16355324-fc8a-45b5-b9e5-7b6e8ac814c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/apache-spark/3.5.5/libexec\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "print(findspark.find())\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import pymongo\n",
    "import certifi\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window as W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c2fdf8-2c35-4152-b60a-5e0ae632f60f",
   "metadata": {},
   "source": [
    "### 2.0. Instantiate Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "977209d2-77d8-40c6-a497-c5c0958c19c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# Specify MySQL Server Connection Information\n",
    "# --------------------------------------------------------------------------------\n",
    "mysql_args = {\n",
    "    \"host_name\" : \"localhost\",\n",
    "    \"port\" : \"3306\",\n",
    "    \"db_name\" : \"northwind_dw\",\n",
    "    \"conn_props\" : {\n",
    "        \"user\" : \"root\",\n",
    "        \"password\" : \"Ashwaniis#1!\",\n",
    "        \"driver\" : \"com.mysql.cj.jdbc.Driver\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Specify MongoDB Cluster Connection Information\n",
    "# --------------------------------------------------------------------------------\n",
    "mongodb_args = {\n",
    "    \"cluster_location\" : \"local\", # \"atlas\"\n",
    "    \"user_name\" : \"vaneeshagupta10\",\n",
    "    \"password\" : \"Fdztq26kWFlyBXiE\",\n",
    "    \"cluster_name\" : \"cluster0\",\n",
    "    \"cluster_subnet\" : \"koqso\",\n",
    "    \"db_name\" : \"northwind\",\n",
    "    \"collection\" : \"\",\n",
    "    \"null_column_threshold\" : 0.5\n",
    "}\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Specify Directory Structure for Source Data\n",
    "# --------------------------------------------------------------------------------\n",
    "base_dir = os.path.join(os.getcwd(), 'lab_data')\n",
    "data_dir = os.path.join(base_dir, 'northwind')\n",
    "batch_dir = os.path.join(data_dir, 'batch')\n",
    "stream_dir = os.path.join(data_dir, 'streaming')\n",
    "\n",
    "orders_stream_dir = os.path.join(stream_dir, 'orders')\n",
    "purchase_orders_stream_dir = os.path.join(stream_dir, 'purchase_orders')\n",
    "inventory_trans_stream_dir = os.path.join(stream_dir, 'inventory_transactions')\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Create Directory Structure for Data Lakehouse Files\n",
    "# --------------------------------------------------------------------------------\n",
    "dest_database = \"northwind_dlh\"\n",
    "sql_warehouse_dir = os.path.abspath('spark-warehouse')\n",
    "dest_database_dir = f\"{dest_database}.db\"\n",
    "database_dir = os.path.join(sql_warehouse_dir, dest_database_dir)\n",
    "\n",
    "orders_output_bronze = os.path.join(database_dir, 'fact_orders', 'bronze')\n",
    "orders_output_silver = os.path.join(database_dir, 'fact_orders', 'silver')\n",
    "orders_output_gold = os.path.join(database_dir, 'fact_orders', 'gold')\n",
    "\n",
    "purchase_orders_output_bronze = os.path.join(database_dir, 'fact_purchase_orders', 'bronze')\n",
    "purchase_orders_output_silver = os.path.join(database_dir, 'fact_purchase_orders', 'silver')\n",
    "purchase_orders_output_gold = os.path.join(database_dir, 'fact_purchase_orders', 'gold')\n",
    "\n",
    "inventory_trans_output_bronze = os.path.join(database_dir, 'fact_inventory_transactions', 'bronze')\n",
    "inventory_trans_output_silver = os.path.join(database_dir, 'fact_inventory_transactions', 'silver')\n",
    "inventory_trans_output_gold = os.path.join(database_dir, 'fact_inventory_transactions', 'gold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021a5185-ad2c-4612-9498-0e2ff4431c5b",
   "metadata": {},
   "source": [
    "### 3.0. Define Global Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2fd4b85-6029-439d-a66a-1cab0a9aa760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_info(path: str):\n",
    "    file_sizes = []\n",
    "    modification_times = []\n",
    "\n",
    "    '''Fetch each item in the directory, and filter out any directories.'''\n",
    "    items = os.listdir(path)\n",
    "    files = sorted([item for item in items if os.path.isfile(os.path.join(path, item))])\n",
    "\n",
    "    '''Populate lists with the Size and Last Modification DateTime for each file in the directory.'''\n",
    "    for file in files:\n",
    "        file_sizes.append(os.path.getsize(os.path.join(path, file)))\n",
    "        modification_times.append(pd.to_datetime(os.path.getmtime(os.path.join(path, file)), unit='s'))\n",
    "\n",
    "    data = list(zip(files, file_sizes, modification_times))\n",
    "    column_names = ['name','size','modification_time']\n",
    "    \n",
    "    return pd.DataFrame(data=data, columns=column_names)\n",
    "\n",
    "\n",
    "def wait_until_stream_is_ready(query, min_batches=1):\n",
    "    while len(query.recentProgress) < min_batches:\n",
    "        time.sleep(5)\n",
    "        \n",
    "    print(f\"The stream has processed {len(query.recentProgress)} batchs\")\n",
    "\n",
    "\n",
    "def remove_directory_tree(path: str):\n",
    "    '''If it exists, remove the entire contents of a directory structure at a given 'path' parameter's location.'''\n",
    "    try:\n",
    "        if os.path.exists(path):\n",
    "            shutil.rmtree(path)\n",
    "            return f\"Directory '{path}' has been removed successfully.\"\n",
    "        else:\n",
    "            return f\"Directory '{path}' does not exist.\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "        \n",
    "\n",
    "def drop_null_columns(df, threshold):\n",
    "    '''Drop Columns having a percentage of NULL values that exceeds the given 'threshold' parameter value.'''\n",
    "    columns_with_nulls = [col for col in df.columns if df.filter(df[col].isNull()).count() / df.count() > threshold] \n",
    "    df_dropped = df.drop(*columns_with_nulls) \n",
    "    \n",
    "    return df_dropped\n",
    "    \n",
    "    \n",
    "def get_mysql_dataframe(spark_session, sql_query : str, **args):\n",
    "    '''Create a JDBC URL to the MySQL Database'''\n",
    "    jdbc_url = f\"jdbc:mysql://{args['host_name']}:{args['port']}/{args['db_name']}\"\n",
    "    \n",
    "    '''Invoke the spark.read.format(\"jdbc\") function to query the database, and fill a DataFrame.'''\n",
    "    dframe = spark_session.read.format(\"jdbc\") \\\n",
    "    .option(\"url\", jdbc_url) \\\n",
    "    .option(\"driver\", args['conn_props']['driver']) \\\n",
    "    .option(\"user\", args['conn_props']['user']) \\\n",
    "    .option(\"password\", args['conn_props']['password']) \\\n",
    "    .option(\"query\", sql_query) \\\n",
    "    .load()\n",
    "    \n",
    "    return dframe\n",
    "    \n",
    "\n",
    "def get_mongo_uri(**args):\n",
    "    '''Validate proper input'''\n",
    "    if args[\"cluster_location\"] not in ['atlas', 'local']:\n",
    "        raise Exception(\"You must specify either 'atlas' or 'local' for the 'cluster_location' parameter.\")\n",
    "        \n",
    "    if args['cluster_location'] == \"atlas\":\n",
    "        uri = f\"mongodb+srv://{args['user_name']}:{args['password']}@\"\n",
    "        uri += f\"{args['cluster_name']}.{args['cluster_subnet']}.mongodb.net/\"\n",
    "    else:\n",
    "        uri = \"mongodb://localhost:27017/\"\n",
    "\n",
    "    return uri\n",
    "\n",
    "\n",
    "def get_spark_conf_args(spark_jars : list, **args):\n",
    "    jars = \"\"\n",
    "    for jar in spark_jars:\n",
    "        jars += f\"{jar}, \"\n",
    "    \n",
    "    sparkConf_args = {\n",
    "        \"app_name\" : \"PySpark Northwind Data Lakehouse (Medallion Architecture)\",\n",
    "        \"worker_threads\" : f\"local[{int(os.cpu_count()/2)}]\",\n",
    "        \"shuffle_partitions\" : int(os.cpu_count()),\n",
    "        \"mongo_uri\" : get_mongo_uri(**args),\n",
    "        \"spark_jars\" : jars[0:-2],\n",
    "        \"database_dir\" : sql_warehouse_dir\n",
    "    }\n",
    "    \n",
    "    return sparkConf_args\n",
    "    \n",
    "\n",
    "def get_spark_conf(**args):\n",
    "    sparkConf = SparkConf().setAppName(args['app_name'])\\\n",
    "    .setMaster(args['worker_threads']) \\\n",
    "    .set('spark.driver.memory', '4g') \\\n",
    "    .set('spark.executor.memory', '2g') \\\n",
    "    .set('spark.jars', args['spark_jars']) \\\n",
    "    .set('spark.jars.packages', 'org.mongodb.spark:mongo-spark-connector_2.12:3.0.1') \\\n",
    "    .set('spark.mongodb.input.uri', args['mongo_uri']) \\\n",
    "    .set('spark.mongodb.output.uri', args['mongo_uri']) \\\n",
    "    .set('spark.sql.adaptive.enabled', 'false') \\\n",
    "    .set('spark.sql.debug.maxToStringFields', 35) \\\n",
    "    .set('spark.sql.shuffle.partitions', args['shuffle_partitions']) \\\n",
    "    .set('spark.sql.streaming.forceDeleteTempCheckpointLocation', 'true') \\\n",
    "    .set('spark.sql.streaming.schemaInference', 'true') \\\n",
    "    .set('spark.sql.warehouse.dir', args['database_dir']) \\\n",
    "    .set('spark.streaming.stopGracefullyOnShutdown', 'true')\n",
    "    \n",
    "    return sparkConf\n",
    "\n",
    "\n",
    "def get_mongo_client(**args):\n",
    "    '''Get MongoDB Client Connection'''\n",
    "    mongo_uri = get_mongo_uri(**args)\n",
    "    if args['cluster_location'] == \"atlas\":\n",
    "        client = pymongo.MongoClient(mongo_uri, tlsCAFile=certifi.where())\n",
    "\n",
    "    elif args['cluster_location'] == \"local\":\n",
    "        client = pymongo.MongoClient(mongo_uri)\n",
    "        \n",
    "    else:\n",
    "        raise Exception(\"A MongoDB Client could not be created.\")\n",
    "\n",
    "    return client\n",
    "    \n",
    "    \n",
    "# TODO: Rewrite this to leverage PySpark?\n",
    "\"\"\" def set_mongo_collections(mongo_client, db_name : str, data_directory : str, json_files : list):\n",
    "    db = mongo_client[db_name]\n",
    "    \n",
    "    for file in json_files:\n",
    "        db.drop_collection(file)\n",
    "        json_file = os.path.join(data_directory, json_files[file])\n",
    "        with open(json_file, 'r') as openfile:\n",
    "            json_object = json.load(openfile)\n",
    "            file = db[file]\n",
    "            result = file.insert_many(json_object)\n",
    "        \n",
    "    mongo_client.close() \"\"\"\n",
    "    \n",
    "def set_mongo_collections_with_pyspark(spark_session, data_directory: str, json_files: dict, **mongo_args):\n",
    "    db_name = mongo_args[\"db_name\"]\n",
    "    mongo_uri = get_mongo_uri(**mongo_args)\n",
    "\n",
    "    for collection_name, filename in json_files.items():\n",
    "        json_file_path = os.path.join(data_directory, filename)\n",
    "\n",
    "        df = spark_session.read \\\n",
    "            .option(\"multiline\", \"true\") \\\n",
    "            .json(json_file_path)\n",
    "\n",
    "        df.write \\\n",
    "            .format(\"com.mongodb.spark.sql.DefaultSource\") \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .option(\"uri\", mongo_uri) \\\n",
    "            .option(\"database\", db_name) \\\n",
    "            .option(\"collection\", collection_name) \\\n",
    "            .save()\n",
    "\n",
    "        print(f\"✔ Loaded {filename} into MongoDB collection '{collection_name}'\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_mongodb_dataframe(spark_session, **args):\n",
    "    '''Query MongoDB, and create a DataFrame'''\n",
    "    dframe = spark_session.read.format(\"com.mongodb.spark.sql.DefaultSource\") \\\n",
    "        .option(\"database\", args['db_name']) \\\n",
    "        .option(\"collection\", args['collection']).load()\n",
    "\n",
    "    '''Drop the '_id' index column to clean up the response.'''\n",
    "    dframe = dframe.drop('_id')\n",
    "    \n",
    "    '''Call the drop_null_columns() function passing in the dataframe.'''\n",
    "    dframe = drop_null_columns(dframe, args['null_column_threshold'])\n",
    "    \n",
    "    return dframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c929bad4-705f-4a01-8d9d-bba2d84d115c",
   "metadata": {},
   "source": [
    "### 4.0. Initialize Data Lakehouse Directory Structure\n",
    "Remove the Data Lakehouse Database Directory Structure to Ensure Idempotency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c09080f-afdc-4969-86cc-0fbd0835faf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Directory '/Users/vaneeshagupta/DS-2002-2/04-PySpark/spark-warehouse/northwind_dlh.db' has been removed successfully.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_directory_tree(database_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa65216-97fc-48d9-b19e-a1f342c53155",
   "metadata": {},
   "source": [
    "### 5.0. Create a New Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a416acc5-71ca-40f5-986a-7eeac55b6317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://vaneeshas-air:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySpark Northwind Data Lakehouse (Medallion Architecture)</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x12865f590>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worker_threads = f\"local[{int(os.cpu_count()/2)}]\"\n",
    "\n",
    "jars = []\n",
    "mysql_spark_jar = os.path.join(os.getcwd(), \"mysql-connector-j-9.1.0\", \"mysql-connector-j-9.1.0.jar\")\n",
    "mssql_spark_jar = os.path.join(os.getcwd(), \"sqljdbc_12.8\", \"enu\", \"jars\", \"mssql-jdbc-12.8.1.jre11.jar\")\n",
    "\n",
    "jars.append(mysql_spark_jar)\n",
    "#jars.append(mssql_spark_jar)\n",
    "\n",
    "sparkConf_args = get_spark_conf_args(jars, **mongodb_args)\n",
    "\n",
    "sparkConf = get_spark_conf(**sparkConf_args)\n",
    "spark = SparkSession.builder.config(conf=sparkConf).getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"OFF\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e8701c-0120-4ba2-81cc-e53ba1f08651",
   "metadata": {},
   "source": [
    "### 6.0. Create a New Metadata Database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "484d76e2-3c95-4d0e-9063-37344aae674c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f\"DROP DATABASE IF EXISTS {dest_database} CASCADE;\")\n",
    "\n",
    "sql_create_db = f\"\"\"\n",
    "    CREATE DATABASE IF NOT EXISTS {dest_database}\n",
    "    COMMENT 'DS-2002 Lab 06 Database'\n",
    "    WITH DBPROPERTIES (contains_pii = true, purpose = 'DS-2002 Lab 6.0');\n",
    "\"\"\"\n",
    "spark.sql(sql_create_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ae5f1c-7ec7-408c-bc89-822b7a75b859",
   "metadata": {},
   "source": [
    "## Section II: Populate Dimensions by Ingesting \"Cold-path\" Reference Data \n",
    "### 1.0. Fetch Data from the File System\n",
    "#### 1.1. Verify the location of the source data files on the file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a3629bc-e7ec-4ed4-9de7-17f648691e4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>size</th>\n",
       "      <th>modification_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>northwind_customers.json</td>\n",
       "      <td>10186</td>\n",
       "      <td>2025-04-21 01:31:03.085003138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>northwind_employees.csv</td>\n",
       "      <td>2687</td>\n",
       "      <td>2025-04-21 01:31:03.085060358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>northwind_invoices.json</td>\n",
       "      <td>5843</td>\n",
       "      <td>2025-04-21 01:31:03.085113764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>northwind_shippers.csv</td>\n",
       "      <td>253</td>\n",
       "      <td>2025-04-21 01:31:03.085165501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>northwind_suppliers.json</td>\n",
       "      <td>1380</td>\n",
       "      <td>2025-04-21 01:31:03.085221767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name   size             modification_time\n",
       "0  northwind_customers.json  10186 2025-04-21 01:31:03.085003138\n",
       "1   northwind_employees.csv   2687 2025-04-21 01:31:03.085060358\n",
       "2   northwind_invoices.json   5843 2025-04-21 01:31:03.085113764\n",
       "3    northwind_shippers.csv    253 2025-04-21 01:31:03.085165501\n",
       "4  northwind_suppliers.json   1380 2025-04-21 01:31:03.085221767"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_file_info(batch_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e13a92a-2e5e-46b3-babc-ac10f20d35da",
   "metadata": {},
   "source": [
    "#### 1.2. Populate the <span style=\"color:darkred\">Employees Dimension</span>\n",
    "##### 1.2.1. Use PySpark to Read data from a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63f9eac0-5c92-4a98-8455-8be2a034d935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vaneeshagupta/DS-2002-2/04-PySpark/lab_data/northwind/batch/northwind_employees.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>company</th>\n",
       "      <th>last_name</th>\n",
       "      <th>first_name</th>\n",
       "      <th>email_address</th>\n",
       "      <th>job_title</th>\n",
       "      <th>business_phone</th>\n",
       "      <th>home_phone</th>\n",
       "      <th>mobile_phone</th>\n",
       "      <th>fax_number</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state_province</th>\n",
       "      <th>zip_postal_code</th>\n",
       "      <th>country_region</th>\n",
       "      <th>web_page</th>\n",
       "      <th>notes</th>\n",
       "      <th>attachments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Northwind Traders</td>\n",
       "      <td>Freehafer</td>\n",
       "      <td>Nancy</td>\n",
       "      <td>nancy@northwindtraders.com</td>\n",
       "      <td>Sales Representative</td>\n",
       "      <td>(123)555-0100</td>\n",
       "      <td>(123)555-0102</td>\n",
       "      <td>NULL</td>\n",
       "      <td>(123)555-0103</td>\n",
       "      <td>123 1st Avenue</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>99999</td>\n",
       "      <td>USA</td>\n",
       "      <td>#http://northwindtraders.com#</td>\n",
       "      <td>NULL</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Northwind Traders</td>\n",
       "      <td>Cencini</td>\n",
       "      <td>Andrew</td>\n",
       "      <td>andrew@northwindtraders.com</td>\n",
       "      <td>Vice President, Sales</td>\n",
       "      <td>(123)555-0100</td>\n",
       "      <td>(123)555-0102</td>\n",
       "      <td>NULL</td>\n",
       "      <td>(123)555-0103</td>\n",
       "      <td>123 2nd Avenue</td>\n",
       "      <td>Bellevue</td>\n",
       "      <td>WA</td>\n",
       "      <td>99999</td>\n",
       "      <td>USA</td>\n",
       "      <td>http://northwindtraders.com#http://northwindtr...</td>\n",
       "      <td>Joined the company as a sales representative, ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id            company  last_name first_name                email_address  \\\n",
       "0   1  Northwind Traders  Freehafer      Nancy   nancy@northwindtraders.com   \n",
       "1   2  Northwind Traders    Cencini     Andrew  andrew@northwindtraders.com   \n",
       "\n",
       "               job_title business_phone     home_phone mobile_phone  \\\n",
       "0   Sales Representative  (123)555-0100  (123)555-0102         NULL   \n",
       "1  Vice President, Sales  (123)555-0100  (123)555-0102         NULL   \n",
       "\n",
       "      fax_number         address      city state_province  zip_postal_code  \\\n",
       "0  (123)555-0103  123 1st Avenue   Seattle             WA            99999   \n",
       "1  (123)555-0103  123 2nd Avenue  Bellevue             WA            99999   \n",
       "\n",
       "  country_region                                           web_page  \\\n",
       "0            USA                      #http://northwindtraders.com#   \n",
       "1            USA  http://northwindtraders.com#http://northwindtr...   \n",
       "\n",
       "                                               notes attachments  \n",
       "0                                               NULL        None  \n",
       "1  Joined the company as a sales representative, ...        None  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employee_csv = os.path.join(batch_dir, 'northwind_employees.csv')\n",
    "print(employee_csv)\n",
    "\n",
    "df_dim_employees = spark.read.format('csv').options(header='true', inferSchema='true').load(employee_csv)\n",
    "df_dim_employees.toPandas().head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e9aedf-9033-403d-a802-b09be878865f",
   "metadata": {},
   "source": [
    "##### 1.2.2. Make Necessary Transformations to the New DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18421cba-8e15-44b0-8328-0ff1f1968936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_key</th>\n",
       "      <th>employee_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>company</th>\n",
       "      <th>job_title</th>\n",
       "      <th>business_phone</th>\n",
       "      <th>home_phone</th>\n",
       "      <th>fax_number</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state_province</th>\n",
       "      <th>zip_postal_code</th>\n",
       "      <th>country_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Nancy</td>\n",
       "      <td>Freehafer</td>\n",
       "      <td>Northwind Traders</td>\n",
       "      <td>Sales Representative</td>\n",
       "      <td>(123)555-0100</td>\n",
       "      <td>(123)555-0102</td>\n",
       "      <td>(123)555-0103</td>\n",
       "      <td>123 1st Avenue</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>99999</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Andrew</td>\n",
       "      <td>Cencini</td>\n",
       "      <td>Northwind Traders</td>\n",
       "      <td>Vice President, Sales</td>\n",
       "      <td>(123)555-0100</td>\n",
       "      <td>(123)555-0102</td>\n",
       "      <td>(123)555-0103</td>\n",
       "      <td>123 2nd Avenue</td>\n",
       "      <td>Bellevue</td>\n",
       "      <td>WA</td>\n",
       "      <td>99999</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_key  employee_id first_name  last_name            company  \\\n",
       "0             1            1      Nancy  Freehafer  Northwind Traders   \n",
       "1             2            2     Andrew    Cencini  Northwind Traders   \n",
       "\n",
       "               job_title business_phone     home_phone     fax_number  \\\n",
       "0   Sales Representative  (123)555-0100  (123)555-0102  (123)555-0103   \n",
       "1  Vice President, Sales  (123)555-0100  (123)555-0102  (123)555-0103   \n",
       "\n",
       "          address      city state_province  zip_postal_code country_region  \n",
       "0  123 1st Avenue   Seattle             WA            99999            USA  \n",
       "1  123 2nd Avenue  Bellevue             WA            99999            USA  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------------------\n",
    "# Rename the 'id' column to 'employee_id' ------------------------------------------\n",
    "# ----------------------------------------------------------------------------------\n",
    "df_dim_employees = df_dim_employees.withColumnRenamed(\"id\", \"employee_id\")\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# Add Primary Key column using SQL Windowing function: ROW_NUMBER() \n",
    "# ----------------------------------------------------------------------------------\n",
    "df_dim_employees.createOrReplaceTempView(\"employees\")\n",
    "sql_employees = f\"\"\"\n",
    "    SELECT *, ROW_NUMBER() OVER (ORDER BY employee_id) AS employee_key\n",
    "    FROM employees;\n",
    "\"\"\"\n",
    "df_dim_employees = spark.sql(sql_employees)\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# Reorder Columns and display the first two rows in a Pandas dataframe\n",
    "# ----------------------------------------------------------------------------------\n",
    "ordered_columns = ['employee_key', 'employee_id', 'first_name', 'last_name'\n",
    "                   , 'company', 'job_title', 'business_phone', 'home_phone', 'fax_number'\n",
    "                   , 'address', 'city', 'state_province', 'zip_postal_code', 'country_region']\n",
    "\n",
    "df_dim_employees = df_dim_employees[ordered_columns]\n",
    "df_dim_employees.toPandas().head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043a826b-085a-42ce-b9b1-f0991e578eb6",
   "metadata": {},
   "source": [
    "##### 1.2.3. Save as the <span style=\"color:darkred\">dim_employees</span> table in the Data Lakehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5931ed64-99f7-4281-b903-a052c89ce6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dim_employees.write.saveAsTable(f\"{dest_database}.dim_employees\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7eacbe-1cad-4ded-9b98-814d140ed8d6",
   "metadata": {},
   "source": [
    "##### 1.2.4. Unit Test: Describe and Preview Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "414f418e-b9aa-4ef0-a256-b7dd3de1519b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+\n",
      "|            col_name|           data_type|comment|\n",
      "+--------------------+--------------------+-------+\n",
      "|        employee_key|                 int|   NULL|\n",
      "|         employee_id|                 int|   NULL|\n",
      "|          first_name|              string|   NULL|\n",
      "|           last_name|              string|   NULL|\n",
      "|             company|              string|   NULL|\n",
      "|           job_title|              string|   NULL|\n",
      "|      business_phone|              string|   NULL|\n",
      "|          home_phone|              string|   NULL|\n",
      "|          fax_number|              string|   NULL|\n",
      "|             address|              string|   NULL|\n",
      "|                city|              string|   NULL|\n",
      "|      state_province|              string|   NULL|\n",
      "|     zip_postal_code|                 int|   NULL|\n",
      "|      country_region|              string|   NULL|\n",
      "|                    |                    |       |\n",
      "|# Detailed Table ...|                    |       |\n",
      "|             Catalog|       spark_catalog|       |\n",
      "|            Database|       northwind_dlh|       |\n",
      "|               Table|       dim_employees|       |\n",
      "|        Created Time|Mon Apr 21 03:37:...|       |\n",
      "+--------------------+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_key</th>\n",
       "      <th>employee_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>company</th>\n",
       "      <th>job_title</th>\n",
       "      <th>business_phone</th>\n",
       "      <th>home_phone</th>\n",
       "      <th>fax_number</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state_province</th>\n",
       "      <th>zip_postal_code</th>\n",
       "      <th>country_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Nancy</td>\n",
       "      <td>Freehafer</td>\n",
       "      <td>Northwind Traders</td>\n",
       "      <td>Sales Representative</td>\n",
       "      <td>(123)555-0100</td>\n",
       "      <td>(123)555-0102</td>\n",
       "      <td>(123)555-0103</td>\n",
       "      <td>123 1st Avenue</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>99999</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Andrew</td>\n",
       "      <td>Cencini</td>\n",
       "      <td>Northwind Traders</td>\n",
       "      <td>Vice President, Sales</td>\n",
       "      <td>(123)555-0100</td>\n",
       "      <td>(123)555-0102</td>\n",
       "      <td>(123)555-0103</td>\n",
       "      <td>123 2nd Avenue</td>\n",
       "      <td>Bellevue</td>\n",
       "      <td>WA</td>\n",
       "      <td>99999</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_key  employee_id first_name  last_name            company  \\\n",
       "0             1            1      Nancy  Freehafer  Northwind Traders   \n",
       "1             2            2     Andrew    Cencini  Northwind Traders   \n",
       "\n",
       "               job_title business_phone     home_phone     fax_number  \\\n",
       "0   Sales Representative  (123)555-0100  (123)555-0102  (123)555-0103   \n",
       "1  Vice President, Sales  (123)555-0100  (123)555-0102  (123)555-0103   \n",
       "\n",
       "          address      city state_province  zip_postal_code country_region  \n",
       "0  123 1st Avenue   Seattle             WA            99999            USA  \n",
       "1  123 2nd Avenue  Bellevue             WA            99999            USA  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f\"DESCRIBE EXTENDED {dest_database}.dim_employees;\").show()\n",
    "spark.sql(f\"SELECT * FROM {dest_database}.dim_employees LIMIT 2\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebca6e1-cf05-44bc-b2c4-29ea6492d5c3",
   "metadata": {},
   "source": [
    "#### 1.3. Populate the <span style=\"color:darkred\">Shippers Dimension</span>\n",
    "##### 1.3.1. Use PySpark to Read Data from a CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "983f5587-5c93-409f-ba2d-d60883a82c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vaneeshagupta/DS-2002-2/04-PySpark/lab_data/northwind/batch/northwind_shippers.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>company</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state_province</th>\n",
       "      <th>zip_postal_code</th>\n",
       "      <th>country_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Shipping Company A</td>\n",
       "      <td>123 Any Street</td>\n",
       "      <td>Memphis</td>\n",
       "      <td>TN</td>\n",
       "      <td>99999</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Shipping Company B</td>\n",
       "      <td>123 Any Street</td>\n",
       "      <td>Memphis</td>\n",
       "      <td>TN</td>\n",
       "      <td>99999</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id             company         address     city state_province  \\\n",
       "0   1  Shipping Company A  123 Any Street  Memphis             TN   \n",
       "1   2  Shipping Company B  123 Any Street  Memphis             TN   \n",
       "\n",
       "   zip_postal_code country_region  \n",
       "0            99999            USA  \n",
       "1            99999            USA  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1). Get a reference to the 'northwind_shippers.csv' file.\n",
    "shippers_csv = os.path.join(batch_dir, 'northwind_shippers.csv')\n",
    "print(shippers_csv)\n",
    "\n",
    "# 2). Use Spark to read the CSV file data into the 'df_dim_shippers' variable.\n",
    "#     Remember to specify that the first row contains column names (header), and to infer the schema.\n",
    "df_dim_shippers = spark.read.format('csv') \\\n",
    "    .option('header', 'true') \\\n",
    "    .option('inferSchema', 'true') \\\n",
    "    .load(shippers_csv)\n",
    "\n",
    "# 3). Unit Test: Convert the spark dataframe to a Pandas dataframe, and display the first two rows.\n",
    "df_dim_shippers.toPandas().head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ce5dcc-59df-4f7e-abf2-604668f77ed4",
   "metadata": {},
   "source": [
    "##### 1.3.2 Make Necessary Transformations to the New DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7498239a-2320-4496-b594-18fb5fe6279d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shipper_key</th>\n",
       "      <th>shipper_id</th>\n",
       "      <th>company</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state_province</th>\n",
       "      <th>zip_postal_code</th>\n",
       "      <th>country_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Shipping Company A</td>\n",
       "      <td>123 Any Street</td>\n",
       "      <td>Memphis</td>\n",
       "      <td>TN</td>\n",
       "      <td>99999</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Shipping Company B</td>\n",
       "      <td>123 Any Street</td>\n",
       "      <td>Memphis</td>\n",
       "      <td>TN</td>\n",
       "      <td>99999</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shipper_key  shipper_id             company         address     city  \\\n",
       "0            1           1  Shipping Company A  123 Any Street  Memphis   \n",
       "1            2           2  Shipping Company B  123 Any Street  Memphis   \n",
       "\n",
       "  state_province  zip_postal_code country_region  \n",
       "0             TN            99999            USA  \n",
       "1             TN            99999            USA  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------------------\n",
    "# Rename the 'id' column to 'shipper_id' ------------------------------------------\n",
    "# ----------------------------------------------------------------------------------\n",
    "df_dim_shippers = df_dim_shippers.withColumnRenamed(\"id\", \"shipper_id\")\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# Add Primary Key column using SQL Windowing function: ROW_NUMBER() \n",
    "# ----------------------------------------------------------------------------------\n",
    "df_dim_shippers.createOrReplaceTempView(\"shippers\")\n",
    "sql_shippers = f\"\"\"\n",
    "    SELECT \n",
    "        ROW_NUMBER() OVER (ORDER BY shipper_id) AS shipper_key,\n",
    "        shipper_id, company, address, city, \n",
    "        state_province, zip_postal_code, country_region\n",
    "    FROM shippers\n",
    "\"\"\"\n",
    "df_dim_shippers = spark.sql(sql_shippers)\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# Reorder Columns and display the first two rows in a Pandas dataframe\n",
    "# ----------------------------------------------------------------------------------\n",
    "ordered_columns = ['shipper_key', 'shipper_id', 'company', 'address', 'city', \n",
    "                   'state_province', 'zip_postal_code', 'country_region']\n",
    "\n",
    "df_dim_shippers = df_dim_shippers[ordered_columns]\n",
    "df_dim_shippers.toPandas().head(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958c325c-2fe6-4c8e-b8c2-aeefb127c3ab",
   "metadata": {},
   "source": [
    "##### 1.3.3. Save as the <span style=\"color:darkred\">dim_shippers</span> table in the Data Lakehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d688f917-d9df-4bee-bd94-1a6147a5558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dim_shippers.write.saveAsTable(f\"{dest_database}.dim_shippers\", mode=\"overwrite\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cb59e9-b2a7-4cd7-b601-9e99857af89e",
   "metadata": {},
   "source": [
    "##### 1.3.4. Unit Test: Describe and Preview Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e73177f0-7590-491e-ae7e-d5256a11dc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+\n",
      "|            col_name|           data_type|comment|\n",
      "+--------------------+--------------------+-------+\n",
      "|         shipper_key|                 int|   NULL|\n",
      "|          shipper_id|                 int|   NULL|\n",
      "|             company|              string|   NULL|\n",
      "|             address|              string|   NULL|\n",
      "|                city|              string|   NULL|\n",
      "|      state_province|              string|   NULL|\n",
      "|     zip_postal_code|                 int|   NULL|\n",
      "|      country_region|              string|   NULL|\n",
      "|                    |                    |       |\n",
      "|# Detailed Table ...|                    |       |\n",
      "|             Catalog|       spark_catalog|       |\n",
      "|            Database|       northwind_dlh|       |\n",
      "|               Table|        dim_shippers|       |\n",
      "|        Created Time|Mon Apr 21 03:51:...|       |\n",
      "|         Last Access|             UNKNOWN|       |\n",
      "|          Created By|         Spark 3.5.5|       |\n",
      "|                Type|             MANAGED|       |\n",
      "|            Provider|             parquet|       |\n",
      "|            Location|file:/Users/vanee...|       |\n",
      "+--------------------+--------------------+-------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shipper_key</th>\n",
       "      <th>shipper_id</th>\n",
       "      <th>company</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state_province</th>\n",
       "      <th>zip_postal_code</th>\n",
       "      <th>country_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Shipping Company A</td>\n",
       "      <td>123 Any Street</td>\n",
       "      <td>Memphis</td>\n",
       "      <td>TN</td>\n",
       "      <td>99999</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Shipping Company B</td>\n",
       "      <td>123 Any Street</td>\n",
       "      <td>Memphis</td>\n",
       "      <td>TN</td>\n",
       "      <td>99999</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shipper_key  shipper_id             company         address     city  \\\n",
       "0            1           1  Shipping Company A  123 Any Street  Memphis   \n",
       "1            2           2  Shipping Company B  123 Any Street  Memphis   \n",
       "\n",
       "  state_province  zip_postal_code country_region  \n",
       "0             TN            99999            USA  \n",
       "1             TN            99999            USA  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f\"DESCRIBE EXTENDED {dest_database}.dim_shippers\").show()\n",
    "spark.sql(f\"SELECT * FROM {dest_database}.dim_shippers LIMIT 2\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c1854d-8ea5-421d-b2d7-62109d67581f",
   "metadata": {},
   "source": [
    "### 2.0. Fetch Reference Data from a MongoDB Atlas Database\n",
    "#### 2.1. Create a New MongoDB Database, and Load Each JSON File into a New MongoDB Collection\n",
    "**NOTE:** The following cell **can** be run more than once because the **set_mongo_collection()** function **is** idempotent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f14ae8b9-128b-49c6-9aeb-532dafdafb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Loaded northwind_customers.json into MongoDB collection 'customers'\n",
      "✔ Loaded northwind_invoices.json into MongoDB collection 'invoices'\n",
      "✔ Loaded northwind_suppliers.json into MongoDB collection 'suppliers'\n"
     ]
    }
   ],
   "source": [
    "#client = get_mongo_client(**mongodb_args)\n",
    "\n",
    "json_files = {\"customers\" : \"northwind_customers.json\",\n",
    "              \"invoices\" : 'northwind_invoices.json',\n",
    "              \"suppliers\" : 'northwind_suppliers.json'\n",
    "             }\n",
    "\n",
    "#set_mongo_collections(client, mongodb_args[\"db_name\"], batch_dir, json_files) \n",
    "set_mongo_collections_with_pyspark(spark, batch_dir, json_files, **mongodb_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1565e612-daeb-45f0-a743-e05b3a137c6e",
   "metadata": {},
   "source": [
    "#### 2.2. Populate the <span style=\"color:darkred\">Customers Dimension</span>\n",
    "##### 2.2.1. Fetch Data from the New MongoDB <span style=\"color:darkred\">Customers</span> Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2b966f7-d6e4-4f51-81b8-871099605278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>business_phone</th>\n",
       "      <th>city</th>\n",
       "      <th>company</th>\n",
       "      <th>country_region</th>\n",
       "      <th>fax_number</th>\n",
       "      <th>first_name</th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>last_name</th>\n",
       "      <th>state_province</th>\n",
       "      <th>zip_postal_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123 1st Street</td>\n",
       "      <td>(123)555-0100</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>Company A</td>\n",
       "      <td>USA</td>\n",
       "      <td>(123)555-0101</td>\n",
       "      <td>Anna</td>\n",
       "      <td>1</td>\n",
       "      <td>Owner</td>\n",
       "      <td>Bedecs</td>\n",
       "      <td>WA</td>\n",
       "      <td>99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123 2nd Street</td>\n",
       "      <td>(123)555-0100</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Company B</td>\n",
       "      <td>USA</td>\n",
       "      <td>(123)555-0101</td>\n",
       "      <td>Antonio</td>\n",
       "      <td>2</td>\n",
       "      <td>Owner</td>\n",
       "      <td>Gratacos Solsona</td>\n",
       "      <td>MA</td>\n",
       "      <td>99999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          address business_phone     city    company country_region  \\\n",
       "0  123 1st Street  (123)555-0100  Seattle  Company A            USA   \n",
       "1  123 2nd Street  (123)555-0100   Boston  Company B            USA   \n",
       "\n",
       "      fax_number first_name  id job_title         last_name state_province  \\\n",
       "0  (123)555-0101       Anna   1     Owner            Bedecs             WA   \n",
       "1  (123)555-0101    Antonio   2     Owner  Gratacos Solsona             MA   \n",
       "\n",
       "  zip_postal_code  \n",
       "0           99999  \n",
       "1           99999  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mongodb_args[\"collection\"] = \"customers\"\n",
    "\n",
    "df_dim_customers = get_mongodb_dataframe(spark, **mongodb_args)\n",
    "df_dim_customers.toPandas().head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59029949-2103-40b8-8393-3707e0e83846",
   "metadata": {},
   "source": [
    "##### 2.2.2. Make Necessary Transformations to the New Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "30819428-fcf7-4668-b080-b124da524417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_key</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>company</th>\n",
       "      <th>last_name</th>\n",
       "      <th>first_name</th>\n",
       "      <th>job_title</th>\n",
       "      <th>business_phone</th>\n",
       "      <th>fax_number</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state_province</th>\n",
       "      <th>zip_postal_code</th>\n",
       "      <th>country_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Company A</td>\n",
       "      <td>Bedecs</td>\n",
       "      <td>Anna</td>\n",
       "      <td>Owner</td>\n",
       "      <td>(123)555-0100</td>\n",
       "      <td>(123)555-0101</td>\n",
       "      <td>123 1st Street</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>99999</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Company B</td>\n",
       "      <td>Gratacos Solsona</td>\n",
       "      <td>Antonio</td>\n",
       "      <td>Owner</td>\n",
       "      <td>(123)555-0100</td>\n",
       "      <td>(123)555-0101</td>\n",
       "      <td>123 2nd Street</td>\n",
       "      <td>Boston</td>\n",
       "      <td>MA</td>\n",
       "      <td>99999</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_key  customer_id    company         last_name first_name  \\\n",
       "0             1            1  Company A            Bedecs       Anna   \n",
       "1             2            2  Company B  Gratacos Solsona    Antonio   \n",
       "\n",
       "  job_title business_phone     fax_number         address     city  \\\n",
       "0     Owner  (123)555-0100  (123)555-0101  123 1st Street  Seattle   \n",
       "1     Owner  (123)555-0100  (123)555-0101  123 2nd Street   Boston   \n",
       "\n",
       "  state_province zip_postal_code country_region  \n",
       "0             WA           99999            USA  \n",
       "1             MA           99999            USA  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------------------\n",
    "# Rename the 'id' column to 'customer_id' ------------------------------------------\n",
    "# ----------------------------------------------------------------------------------\n",
    "df_dim_customers = df_dim_customers.withColumnRenamed(\"id\", \"customer_id\")\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# Add Primary Key column using the SQL Windowing function: ROW_NUMBER() \n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "df_dim_customers.createOrReplaceTempView(\"customers\")\n",
    "sql_customers = \"\"\"\n",
    "    SELECT \n",
    "        ROW_NUMBER() OVER (ORDER BY customer_id) AS customer_key,\n",
    "        customer_id,\n",
    "        company,\n",
    "        last_name,\n",
    "        first_name,\n",
    "        job_title,\n",
    "        business_phone,\n",
    "        fax_number,\n",
    "        address,\n",
    "        city,\n",
    "        state_province,\n",
    "        zip_postal_code,\n",
    "        country_region\n",
    "    FROM customers\n",
    "\"\"\"\n",
    "df_dim_customers = spark.sql(sql_customers)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# Reorder Columns and display the first two rows in a Pandas dataframe\n",
    "# ----------------------------------------------------------------------------------\n",
    "# Reorder Columns and display the first two rows in a Pandas dataframe\n",
    "ordered_columns = ['customer_key', 'customer_id', 'company', 'last_name', 'first_name',\n",
    "                   'job_title', 'business_phone', 'fax_number',\n",
    "                   'address', 'city', 'state_province', 'zip_postal_code', 'country_region']\n",
    "\n",
    "df_dim_customers = df_dim_customers.select(*ordered_columns)\n",
    "df_dim_customers.toPandas().head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c71d4b7-b620-49db-ba43-0b5c83b77b61",
   "metadata": {},
   "source": [
    "##### 2.2.3. Save as the <span style=\"color:darkred\">dim_customers</span> table in the Data lakehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d3467a6d-8037-4d25-b9c1-18e9bbc413c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dim_customers.write.saveAsTable(f\"{dest_database}.dim_customers\", mode=\"overwrite\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d8d82a-dba4-40e3-aecc-0f4763b94679",
   "metadata": {},
   "source": [
    "##### 2.2.4. Unit Test: Describe and Preview Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "64add729-9a97-483c-874e-c5aede8eadc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+\n",
      "|            col_name|           data_type|comment|\n",
      "+--------------------+--------------------+-------+\n",
      "|        customer_key|                 int|   NULL|\n",
      "|         customer_id|              bigint|   NULL|\n",
      "|             company|              string|   NULL|\n",
      "|           last_name|              string|   NULL|\n",
      "|          first_name|              string|   NULL|\n",
      "|           job_title|              string|   NULL|\n",
      "|      business_phone|              string|   NULL|\n",
      "|          fax_number|              string|   NULL|\n",
      "|             address|              string|   NULL|\n",
      "|                city|              string|   NULL|\n",
      "|      state_province|              string|   NULL|\n",
      "|     zip_postal_code|              string|   NULL|\n",
      "|      country_region|              string|   NULL|\n",
      "|                    |                    |       |\n",
      "|# Detailed Table ...|                    |       |\n",
      "|             Catalog|       spark_catalog|       |\n",
      "|            Database|       northwind_dlh|       |\n",
      "|               Table|       dim_customers|       |\n",
      "|        Created Time|Mon Apr 21 03:59:...|       |\n",
      "|         Last Access|             UNKNOWN|       |\n",
      "+--------------------+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_key</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>company</th>\n",
       "      <th>last_name</th>\n",
       "      <th>first_name</th>\n",
       "      <th>job_title</th>\n",
       "      <th>business_phone</th>\n",
       "      <th>fax_number</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state_province</th>\n",
       "      <th>zip_postal_code</th>\n",
       "      <th>country_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Company A</td>\n",
       "      <td>Bedecs</td>\n",
       "      <td>Anna</td>\n",
       "      <td>Owner</td>\n",
       "      <td>(123)555-0100</td>\n",
       "      <td>(123)555-0101</td>\n",
       "      <td>123 1st Street</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>99999</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Company B</td>\n",
       "      <td>Gratacos Solsona</td>\n",
       "      <td>Antonio</td>\n",
       "      <td>Owner</td>\n",
       "      <td>(123)555-0100</td>\n",
       "      <td>(123)555-0101</td>\n",
       "      <td>123 2nd Street</td>\n",
       "      <td>Boston</td>\n",
       "      <td>MA</td>\n",
       "      <td>99999</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_key  customer_id    company         last_name first_name  \\\n",
       "0             1            1  Company A            Bedecs       Anna   \n",
       "1             2            2  Company B  Gratacos Solsona    Antonio   \n",
       "\n",
       "  job_title business_phone     fax_number         address     city  \\\n",
       "0     Owner  (123)555-0100  (123)555-0101  123 1st Street  Seattle   \n",
       "1     Owner  (123)555-0100  (123)555-0101  123 2nd Street   Boston   \n",
       "\n",
       "  state_province zip_postal_code country_region  \n",
       "0             WA           99999            USA  \n",
       "1             MA           99999            USA  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f\"DESCRIBE EXTENDED {dest_database}.dim_customers\").show()\n",
    "spark.sql(f\"SELECT * FROM {dest_database}.dim_customers LIMIT 2\").toPandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e3947d-c807-4bdb-8552-bb6ec0389574",
   "metadata": {},
   "source": [
    "#### 2.4. Populate the <span style=\"color:darkred\">Suppliers Dimension</span>\n",
    "##### 2.3.1. Fetch Data from the New MongoDB <span style=\"color:darkred\">Suppliers</span> Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c122223-74ee-4dd2-b506-8e6fcd85b028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- company: string (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- job_title: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>first_name</th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>last_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Supplier A</td>\n",
       "      <td>Elizabeth A.</td>\n",
       "      <td>1</td>\n",
       "      <td>Sales Manager</td>\n",
       "      <td>Andersen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Supplier B</td>\n",
       "      <td>Cornelia</td>\n",
       "      <td>2</td>\n",
       "      <td>Sales Manager</td>\n",
       "      <td>Weiler</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      company    first_name  id      job_title last_name\n",
       "0  Supplier A  Elizabeth A.   1  Sales Manager  Andersen\n",
       "1  Supplier B      Cornelia   2  Sales Manager    Weiler"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mongodb_args[\"collection\"] = \"suppliers\"\n",
    "df_dim_suppliers = get_mongodb_dataframe(spark, **mongodb_args)\n",
    "df_dim_suppliers.printSchema()\n",
    "df_dim_suppliers.toPandas().head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcc6f32-aecc-475d-8b37-f775b89f9356",
   "metadata": {},
   "source": [
    "##### 2.3.2. Make Necessary Transformations to the New Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fb757e10-4c6f-4210-b9ce-29894a1d30dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>supplier_key</th>\n",
       "      <th>supplier_id</th>\n",
       "      <th>company</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>job_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Supplier A</td>\n",
       "      <td>Elizabeth A.</td>\n",
       "      <td>Andersen</td>\n",
       "      <td>Sales Manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Supplier B</td>\n",
       "      <td>Cornelia</td>\n",
       "      <td>Weiler</td>\n",
       "      <td>Sales Manager</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   supplier_key  supplier_id     company    first_name last_name  \\\n",
       "0             1            1  Supplier A  Elizabeth A.  Andersen   \n",
       "1             2            2  Supplier B      Cornelia    Weiler   \n",
       "\n",
       "       job_title  \n",
       "0  Sales Manager  \n",
       "1  Sales Manager  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------------------\n",
    "# Rename the 'id' column to 'supplier_id' ------------------------------------------\n",
    "# ----------------------------------------------------------------------------------\n",
    "df_dim_suppliers = df_dim_suppliers.withColumnRenamed(\"id\", \"supplier_id\")\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# Add Primary Key column using SQL Windowing function: ROW_NUMBER() \n",
    "# ----------------------------------------------------------------------------------\n",
    "df_dim_suppliers.createOrReplaceTempView(\"suppliers\")\n",
    "sql_suppliers = \"\"\"\n",
    "    SELECT \n",
    "        ROW_NUMBER() OVER (ORDER BY supplier_id) AS supplier_key,\n",
    "        supplier_id,\n",
    "        company,\n",
    "        first_name,\n",
    "        last_name,\n",
    "        job_title\n",
    "    FROM suppliers\n",
    "\"\"\"\n",
    "df_dim_suppliers = spark.sql(sql_suppliers)\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# Reorder Columns and display the first two rows in a Pandas dataframe\n",
    "# ----------------------------------------------------------------------------------\n",
    "ordered_columns = ['supplier_key', 'supplier_id', 'company', 'first_name', 'last_name', 'job_title']\n",
    "df_dim_suppliers = df_dim_suppliers.select(*ordered_columns)\n",
    "df_dim_suppliers.toPandas().head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47e1dde-546d-40d9-9c2d-dd56ea7aad03",
   "metadata": {},
   "source": [
    "##### 2.3.3. Save as the <span style=\"color:darkred\">dim_suppliers</span> table in the Data lakehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "242e4322-4e8a-4279-92b8-0eaa18ee871e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dim_suppliers.write.saveAsTable(f\"{dest_database}.dim_suppliers\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b525fa75-7fca-445f-a586-5d8acf995f6e",
   "metadata": {},
   "source": [
    "##### 2.3.4. Unit Test: Describe and Preview Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f390f44-e113-49f3-8ac7-8c864bed2ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+\n",
      "|            col_name|           data_type|comment|\n",
      "+--------------------+--------------------+-------+\n",
      "|        supplier_key|                 int|   NULL|\n",
      "|         supplier_id|              bigint|   NULL|\n",
      "|             company|              string|   NULL|\n",
      "|          first_name|              string|   NULL|\n",
      "|           last_name|              string|   NULL|\n",
      "|           job_title|              string|   NULL|\n",
      "|                    |                    |       |\n",
      "|# Detailed Table ...|                    |       |\n",
      "|             Catalog|       spark_catalog|       |\n",
      "|            Database|       northwind_dlh|       |\n",
      "|               Table|       dim_suppliers|       |\n",
      "|        Created Time|Mon Apr 21 04:03:...|       |\n",
      "|         Last Access|             UNKNOWN|       |\n",
      "|          Created By|         Spark 3.5.5|       |\n",
      "|                Type|             MANAGED|       |\n",
      "|            Provider|             parquet|       |\n",
      "|            Location|file:/Users/vanee...|       |\n",
      "+--------------------+--------------------+-------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>supplier_key</th>\n",
       "      <th>supplier_id</th>\n",
       "      <th>company</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>job_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Supplier A</td>\n",
       "      <td>Elizabeth A.</td>\n",
       "      <td>Andersen</td>\n",
       "      <td>Sales Manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Supplier B</td>\n",
       "      <td>Cornelia</td>\n",
       "      <td>Weiler</td>\n",
       "      <td>Sales Manager</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   supplier_key  supplier_id     company    first_name last_name  \\\n",
       "0             1            1  Supplier A  Elizabeth A.  Andersen   \n",
       "1             2            2  Supplier B      Cornelia    Weiler   \n",
       "\n",
       "       job_title  \n",
       "0  Sales Manager  \n",
       "1  Sales Manager  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f\"DESCRIBE EXTENDED {dest_database}.dim_suppliers\").show()\n",
    "spark.sql(f\"SELECT * FROM {dest_database}.dim_suppliers LIMIT 2\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11cf43d-c4be-446a-bdf9-73400fab4561",
   "metadata": {},
   "source": [
    "#### 2.4. Populate the <span style=\"color:darkred\">Invoices Dimension</span>\n",
    "##### 2.4.1. Fetch Data from the New MongoDB <span style=\"color:darkred\">Invoices</span> Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8c2f01d2-1a8e-445a-9913-549b06c783ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- amount_due: double (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- invoice_date: string (nullable = true)\n",
      " |-- order_id: long (nullable = true)\n",
      " |-- shipping: double (nullable = true)\n",
      " |-- tax: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount_due</th>\n",
       "      <th>id</th>\n",
       "      <th>invoice_date</th>\n",
       "      <th>order_id</th>\n",
       "      <th>shipping</th>\n",
       "      <th>tax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2006-03-22 16:08:59</td>\n",
       "      <td>31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2006-03-22 16:10:27</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amount_due  id         invoice_date  order_id  shipping  tax\n",
       "0         0.0   5  2006-03-22 16:08:59        31       0.0  0.0\n",
       "1         0.0   6  2006-03-22 16:10:27        32       0.0  0.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mongodb_args[\"collection\"] = \"invoices\"\n",
    "df_dim_invoices = get_mongodb_dataframe(spark, **mongodb_args)\n",
    "df_dim_invoices.printSchema()\n",
    "df_dim_invoices.toPandas().head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe339fa3-907d-4e5a-9f72-3cd71e179a84",
   "metadata": {},
   "source": [
    "##### 2.4.2. Make Necessary Transformations to the New Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8e7dc00b-1241-4463-9d07-35066896cba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>invoice_key</th>\n",
       "      <th>invoice_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>invoice_date</th>\n",
       "      <th>tax</th>\n",
       "      <th>shipping</th>\n",
       "      <th>amount_due</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>2006-03-22 16:08:59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>32</td>\n",
       "      <td>2006-03-22 16:10:27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   invoice_key  invoice_id  order_id         invoice_date  tax  shipping  \\\n",
       "0            1           5        31  2006-03-22 16:08:59  0.0       0.0   \n",
       "1            2           6        32  2006-03-22 16:10:27  0.0       0.0   \n",
       "\n",
       "   amount_due  \n",
       "0         0.0  \n",
       "1         0.0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------------------\n",
    "# Rename the 'id' column to 'invoice_id' ------------------------------------------\n",
    "# ----------------------------------------------------------------------------------\n",
    "df_dim_invoices = df_dim_invoices.withColumnRenamed(\"id\", \"invoice_id\")\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# Add Primary Key column using SQL Windowing function: ROW_NUMBER() \n",
    "# ----------------------------------------------------------------------------------\n",
    "df_dim_invoices.createOrReplaceTempView(\"invoices\")\n",
    "sql_invoices = \"\"\"\n",
    "    SELECT \n",
    "        ROW_NUMBER() OVER (ORDER BY invoice_id) AS invoice_key,\n",
    "        invoice_id,\n",
    "        order_id,\n",
    "        invoice_date,\n",
    "        tax,\n",
    "        shipping,\n",
    "        amount_due\n",
    "    FROM invoices\n",
    "\"\"\"\n",
    "df_dim_invoices = spark.sql(sql_invoices)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# Reorder Columns and display the first two rows in a Pandas dataframe\n",
    "# ----------------------------------------------------------------------------------\n",
    "ordered_columns = ['invoice_key', 'invoice_id', 'order_id', 'invoice_date',\n",
    "                   'tax', 'shipping', 'amount_due']\n",
    "\n",
    "df_dim_invoices = df_dim_invoices.select(*ordered_columns)\n",
    "df_dim_invoices.toPandas().head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c3fc36-487a-4342-b47f-c2cbc04f27b4",
   "metadata": {},
   "source": [
    "##### 2.4.3. Save as the <span style=\"color:darkred\">dim_invoices</span> table in the Data lakehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "76518f9d-133a-4c8a-969b-6ed014fd028f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dim_invoices.write.saveAsTable(f\"{dest_database}.dim_invoices\", mode=\"overwrite\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e9d072-764d-478e-80d7-f5b84f6618b3",
   "metadata": {},
   "source": [
    "##### 2.4.4. Unit Test: Describe and Preview Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8b046075-3b8f-45fb-a5ce-235862429603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+\n",
      "|            col_name|           data_type|comment|\n",
      "+--------------------+--------------------+-------+\n",
      "|         invoice_key|                 int|   NULL|\n",
      "|          invoice_id|              bigint|   NULL|\n",
      "|            order_id|              bigint|   NULL|\n",
      "|        invoice_date|              string|   NULL|\n",
      "|                 tax|              double|   NULL|\n",
      "|            shipping|              double|   NULL|\n",
      "|          amount_due|              double|   NULL|\n",
      "|                    |                    |       |\n",
      "|# Detailed Table ...|                    |       |\n",
      "|             Catalog|       spark_catalog|       |\n",
      "|            Database|       northwind_dlh|       |\n",
      "|               Table|        dim_invoices|       |\n",
      "|        Created Time|Mon Apr 21 04:05:...|       |\n",
      "|         Last Access|             UNKNOWN|       |\n",
      "|          Created By|         Spark 3.5.5|       |\n",
      "|                Type|             MANAGED|       |\n",
      "|            Provider|             parquet|       |\n",
      "|            Location|file:/Users/vanee...|       |\n",
      "+--------------------+--------------------+-------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>invoice_key</th>\n",
       "      <th>invoice_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>invoice_date</th>\n",
       "      <th>tax</th>\n",
       "      <th>shipping</th>\n",
       "      <th>amount_due</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>2006-03-22 16:08:59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>32</td>\n",
       "      <td>2006-03-22 16:10:27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   invoice_key  invoice_id  order_id         invoice_date  tax  shipping  \\\n",
       "0            1           5        31  2006-03-22 16:08:59  0.0       0.0   \n",
       "1            2           6        32  2006-03-22 16:10:27  0.0       0.0   \n",
       "\n",
       "   amount_due  \n",
       "0         0.0  \n",
       "1         0.0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f\"DESCRIBE EXTENDED {dest_database}.dim_invoices\").show()\n",
    "spark.sql(f\"SELECT * FROM {dest_database}.dim_invoices LIMIT 2\").toPandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8947777-e4a6-461f-9490-301ccaf4b06a",
   "metadata": {},
   "source": [
    "### 3.0. Fetch Reference Data from a MySQL Database\n",
    "#### 3.1. Populate the <span style=\"color:darkred\">Date Dimension</span>\n",
    "##### 3.1.1 Fetch data from the <span style=\"color:darkred\">dim_date</span> table in MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0f4af01d-9f24-4287-87cd-07fc31502958",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_dim_date = f\"SELECT * FROM {mysql_args['db_name']}.dim_date\"\n",
    "df_dim_date = get_mysql_dataframe(spark, sql_dim_date, **mysql_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23be56fc-b6e3-42e1-801d-3474957aee4a",
   "metadata": {},
   "source": [
    "##### 3.1.2. Save as the <span style=\"color:darkred\">dim_date</span> table in the Data Lakehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "868fc437-5f13-447e-8def-1fc663eb05a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dim_date.write.saveAsTable(f\"{dest_database}.dim_date\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f64095-6b91-43b4-b96f-20d4fafa9a35",
   "metadata": {},
   "source": [
    "##### 3.1.3. Unit Test: Describe and Preview Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a08f8ad8-b44d-4a82-bd4e-d94757964c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-------+\n",
      "|            col_name|data_type|comment|\n",
      "+--------------------+---------+-------+\n",
      "|            date_key|      int|   NULL|\n",
      "|           full_date|     date|   NULL|\n",
      "|           date_name| char(11)|   NULL|\n",
      "|        date_name_us| char(11)|   NULL|\n",
      "|        date_name_eu| char(11)|   NULL|\n",
      "|         day_of_week|  tinyint|   NULL|\n",
      "|    day_name_of_week| char(10)|   NULL|\n",
      "|        day_of_month|  tinyint|   NULL|\n",
      "|         day_of_year|      int|   NULL|\n",
      "|     weekday_weekend| char(10)|   NULL|\n",
      "|        week_of_year|  tinyint|   NULL|\n",
      "|          month_name| char(10)|   NULL|\n",
      "|       month_of_year|  tinyint|   NULL|\n",
      "|is_last_day_of_month|  char(1)|   NULL|\n",
      "|    calendar_quarter|  tinyint|   NULL|\n",
      "|       calendar_year|      int|   NULL|\n",
      "| calendar_year_month| char(10)|   NULL|\n",
      "|   calendar_year_qtr| char(10)|   NULL|\n",
      "|fiscal_month_of_year|  tinyint|   NULL|\n",
      "|      fiscal_quarter|  tinyint|   NULL|\n",
      "+--------------------+---------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_key</th>\n",
       "      <th>full_date</th>\n",
       "      <th>date_name</th>\n",
       "      <th>date_name_us</th>\n",
       "      <th>date_name_eu</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_name_of_week</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>weekday_weekend</th>\n",
       "      <th>...</th>\n",
       "      <th>is_last_day_of_month</th>\n",
       "      <th>calendar_quarter</th>\n",
       "      <th>calendar_year</th>\n",
       "      <th>calendar_year_month</th>\n",
       "      <th>calendar_year_qtr</th>\n",
       "      <th>fiscal_month_of_year</th>\n",
       "      <th>fiscal_quarter</th>\n",
       "      <th>fiscal_year</th>\n",
       "      <th>fiscal_year_month</th>\n",
       "      <th>fiscal_year_qtr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000101</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>2000/01/01</td>\n",
       "      <td>01/01/2000</td>\n",
       "      <td>01/01/2000</td>\n",
       "      <td>7</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000-01</td>\n",
       "      <td>2000Q1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000-07</td>\n",
       "      <td>2000Q3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000102</td>\n",
       "      <td>2000-01-02</td>\n",
       "      <td>2000/01/02</td>\n",
       "      <td>01/02/2000</td>\n",
       "      <td>02/01/2000</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000-01</td>\n",
       "      <td>2000Q1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000-07</td>\n",
       "      <td>2000Q3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_key   full_date    date_name date_name_us date_name_eu  day_of_week  \\\n",
       "0  20000101  2000-01-01  2000/01/01   01/01/2000   01/01/2000             7   \n",
       "1  20000102  2000-01-02  2000/01/02   01/02/2000   02/01/2000             1   \n",
       "\n",
       "  day_name_of_week  day_of_month  day_of_year weekday_weekend  ...  \\\n",
       "0       Saturday               1            1      Weekend     ...   \n",
       "1       Sunday                 2            2      Weekend     ...   \n",
       "\n",
       "   is_last_day_of_month calendar_quarter  calendar_year calendar_year_month  \\\n",
       "0                     N                1           2000          2000-01      \n",
       "1                     N                1           2000          2000-01      \n",
       "\n",
       "   calendar_year_qtr  fiscal_month_of_year fiscal_quarter fiscal_year  \\\n",
       "0         2000Q1                         7              3        2000   \n",
       "1         2000Q1                         7              3        2000   \n",
       "\n",
       "   fiscal_year_month  fiscal_year_qtr  \n",
       "0         2000-07          2000Q3      \n",
       "1         2000-07          2000Q3      \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f\"DESCRIBE EXTENDED {dest_database}.dim_date;\").show()\n",
    "spark.sql(f\"SELECT * FROM {dest_database}.dim_date LIMIT 2\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df0a18f-6a72-4b02-b4a7-f41080d0ca4d",
   "metadata": {},
   "source": [
    "#### 3.2. Populate the <span style=\"color:darkred\">Product Dimension</span>\n",
    "##### 3.2.1. Fetch data from the <span style=\"color:darkred\">Products</span> table in MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ff551005-e91d-4dd4-9b2a-36326b0d73ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- supplier_ids: string (nullable = true)\n",
      " |-- id: integer (nullable = true)\n",
      " |-- product_code: string (nullable = true)\n",
      " |-- product_name: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- standard_cost: decimal(19,4) (nullable = true)\n",
      " |-- list_price: decimal(19,4) (nullable = true)\n",
      " |-- reorder_level: integer (nullable = true)\n",
      " |-- target_level: integer (nullable = true)\n",
      " |-- quantity_per_unit: string (nullable = true)\n",
      " |-- discontinued: boolean (nullable = true)\n",
      " |-- minimum_reorder_quantity: integer (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- attachments: binary (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------------------\n",
    "# Add Primary Key column using the SQL Windowing function: ROW_NUMBER() \n",
    "# ----------------------------------------------------------------------------------\n",
    "mysql_args[\"db_name\"] = \"northwind\"\n",
    "\n",
    "sql_dim_products = f\"SELECT * FROM {mysql_args['db_name']}.products\"\n",
    "df_dim_products = get_mysql_dataframe(spark, sql_dim_products, **mysql_args)\n",
    "\n",
    "df_dim_products.printSchema()\n",
    "df_dim_products.toPandas().head(2)\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "\n",
    "window_spec = Window.orderBy(\"id\")\n",
    "df_dim_products = df_dim_products.withColumn(\"product_key\", row_number().over(window_spec))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b715baa-4e46-40dd-9cd1-eeafbaefa977",
   "metadata": {},
   "source": [
    "##### 3.2.2. Perform any Necessary Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "26d6d060-81e9-4929-b41a-a8444ec62405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_key</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_code</th>\n",
       "      <th>product_name</th>\n",
       "      <th>standard_cost</th>\n",
       "      <th>list_price</th>\n",
       "      <th>reorder_level</th>\n",
       "      <th>target_level</th>\n",
       "      <th>quantity_per_unit</th>\n",
       "      <th>discontinued</th>\n",
       "      <th>minimum_reorder_quantity</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NWTB-1</td>\n",
       "      <td>Northwind Traders Chai</td>\n",
       "      <td>13.5000</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>10 boxes x 20 bags</td>\n",
       "      <td>False</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Beverages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NWTCO-3</td>\n",
       "      <td>Northwind Traders Syrup</td>\n",
       "      <td>7.5000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>12 - 550 ml bottles</td>\n",
       "      <td>False</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Condiments</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_key  product_id product_code             product_name  \\\n",
       "0            1           1       NWTB-1   Northwind Traders Chai   \n",
       "1            2           3      NWTCO-3  Northwind Traders Syrup   \n",
       "\n",
       "  standard_cost list_price  reorder_level  target_level    quantity_per_unit  \\\n",
       "0       13.5000    18.0000             10            40   10 boxes x 20 bags   \n",
       "1        7.5000    10.0000             25           100  12 - 550 ml bottles   \n",
       "\n",
       "   discontinued  minimum_reorder_quantity    category  \n",
       "0         False                      10.0   Beverages  \n",
       "1         False                      25.0  Condiments  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------------------\n",
    "# Rename the 'id' column to 'product_id' \n",
    "# ----------------------------------------------------------------------------------\n",
    "# Using the monotonically_increasing_id() function has some limitations: starts with zero (0), and is not sequential.\n",
    "    # df_dim_products = df_dim_products.withColumn(\"product_key\", monotonically_increasing_id())\n",
    "df_dim_products = df_dim_products.withColumnRenamed(\"id\", \"product_id\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# Drop unwanted columns (description and attachments)\n",
    "# ----------------------------------------------------------------------------------\n",
    "df_dim_products = df_dim_products.drop(\"description\", \"attachments\")\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# Reorder Columns and display the first two rows in a Pandas dataframe\n",
    "# ----------------------------------------------------------------------------------\n",
    "ordered_columns = [\n",
    "    \"product_key\", \"product_id\", \"product_code\", \"product_name\",\n",
    "    \"standard_cost\", \"list_price\", \"reorder_level\", \"target_level\",\n",
    "    \"quantity_per_unit\", \"discontinued\", \"minimum_reorder_quantity\", \"category\"\n",
    "]\n",
    "\n",
    "df_dim_products = df_dim_products.select(*ordered_columns)\n",
    "df_dim_products.toPandas().head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e24d3a-7dfd-45d6-ae1e-a5023ed4e420",
   "metadata": {},
   "source": [
    "##### 3.2.3. Save as the <span style=\"color:darkred\">dim_products</span> table in the Data Lakehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b76683fe-db95-4ab7-934e-e3d28bc4e717",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dim_products.write.saveAsTable(f\"{dest_database}.dim_products\", mode=\"overwrite\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6942bdac-df24-4e80-bd1b-e1dc276d2c34",
   "metadata": {},
   "source": [
    "##### 3.2.4. Unit Test: Describe and Preview Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7a723db4-148f-4a75-a40c-dac99aab3559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+----------------------------+-------+\n",
      "|col_name                    |data_type                   |comment|\n",
      "+----------------------------+----------------------------+-------+\n",
      "|product_key                 |int                         |NULL   |\n",
      "|product_id                  |int                         |NULL   |\n",
      "|product_code                |varchar(25)                 |NULL   |\n",
      "|product_name                |varchar(50)                 |NULL   |\n",
      "|standard_cost               |decimal(19,4)               |NULL   |\n",
      "|list_price                  |decimal(19,4)               |NULL   |\n",
      "|reorder_level               |int                         |NULL   |\n",
      "|target_level                |int                         |NULL   |\n",
      "|quantity_per_unit           |varchar(50)                 |NULL   |\n",
      "|discontinued                |boolean                     |NULL   |\n",
      "|minimum_reorder_quantity    |int                         |NULL   |\n",
      "|category                    |varchar(50)                 |NULL   |\n",
      "|                            |                            |       |\n",
      "|# Detailed Table Information|                            |       |\n",
      "|Catalog                     |spark_catalog               |       |\n",
      "|Database                    |northwind_dlh               |       |\n",
      "|Table                       |dim_products                |       |\n",
      "|Created Time                |Mon Apr 21 04:38:59 EDT 2025|       |\n",
      "|Last Access                 |UNKNOWN                     |       |\n",
      "|Created By                  |Spark 3.5.5                 |       |\n",
      "+----------------------------+----------------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_key</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_code</th>\n",
       "      <th>product_name</th>\n",
       "      <th>standard_cost</th>\n",
       "      <th>list_price</th>\n",
       "      <th>reorder_level</th>\n",
       "      <th>target_level</th>\n",
       "      <th>quantity_per_unit</th>\n",
       "      <th>discontinued</th>\n",
       "      <th>minimum_reorder_quantity</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NWTB-1</td>\n",
       "      <td>Northwind Traders Chai</td>\n",
       "      <td>13.5000</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>10 boxes x 20 bags</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>Beverages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NWTCO-3</td>\n",
       "      <td>Northwind Traders Syrup</td>\n",
       "      <td>7.5000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>12 - 550 ml bottles</td>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "      <td>Condiments</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_key  product_id product_code             product_name  \\\n",
       "0            1           1       NWTB-1   Northwind Traders Chai   \n",
       "1            2           3      NWTCO-3  Northwind Traders Syrup   \n",
       "\n",
       "  standard_cost list_price  reorder_level  target_level    quantity_per_unit  \\\n",
       "0       13.5000    18.0000             10            40   10 boxes x 20 bags   \n",
       "1        7.5000    10.0000             25           100  12 - 550 ml bottles   \n",
       "\n",
       "   discontinued  minimum_reorder_quantity    category  \n",
       "0         False                        10   Beverages  \n",
       "1         False                        25  Condiments  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f\"DESCRIBE EXTENDED {dest_database}.dim_products\").show(truncate=False)\n",
    "spark.sql(f\"SELECT * FROM {dest_database}.dim_products LIMIT 2\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375bf727-5f3e-4589-a4da-d57446a376f3",
   "metadata": {},
   "source": [
    "### 4.0. Verify Dimension Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "29795432-f447-4c0b-a5a1-cc7d4b4fb008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>namespace</th>\n",
       "      <th>tableName</th>\n",
       "      <th>isTemporary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>northwind_dlh</td>\n",
       "      <td>dim_customers</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>northwind_dlh</td>\n",
       "      <td>dim_date</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>northwind_dlh</td>\n",
       "      <td>dim_employees</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>northwind_dlh</td>\n",
       "      <td>dim_invoices</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>northwind_dlh</td>\n",
       "      <td>dim_products</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>northwind_dlh</td>\n",
       "      <td>dim_shippers</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>northwind_dlh</td>\n",
       "      <td>dim_suppliers</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>customers</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>employees</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>invoices</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>shippers</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>suppliers</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        namespace      tableName  isTemporary\n",
       "0   northwind_dlh  dim_customers        False\n",
       "1   northwind_dlh       dim_date        False\n",
       "2   northwind_dlh  dim_employees        False\n",
       "3   northwind_dlh   dim_invoices        False\n",
       "4   northwind_dlh   dim_products        False\n",
       "5   northwind_dlh   dim_shippers        False\n",
       "6   northwind_dlh  dim_suppliers        False\n",
       "7                      customers         True\n",
       "8                      employees         True\n",
       "9                       invoices         True\n",
       "10                      shippers         True\n",
       "11                     suppliers         True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f\"USE {dest_database};\")\n",
    "spark.sql(\"SHOW TABLES\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f158f3-15d4-4b77-8080-c3d1bc68986a",
   "metadata": {},
   "source": [
    "## Section III: Integrate Reference Data with Real-Time Data\n",
    "### 6.0. Use PySpark Structured Streaming to Process (Hot Path) <span style=\"color:darkred\">Orders</span> Fact Data  \n",
    "#### 6.1. Verify the location of the source data files on the file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2b506c14-a897-4ac8-a01e-590ddc2e49b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>size</th>\n",
       "      <th>modification_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>northwind_orders_01.json</td>\n",
       "      <td>9609</td>\n",
       "      <td>2025-04-21 01:31:03.085644722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>northwind_orders_02.json</td>\n",
       "      <td>9103</td>\n",
       "      <td>2025-04-21 01:31:03.085706472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>northwind_orders_03.json</td>\n",
       "      <td>9008</td>\n",
       "      <td>2025-04-21 01:31:03.085754871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name  size             modification_time\n",
       "0  northwind_orders_01.json  9609 2025-04-21 01:31:03.085644722\n",
       "1  northwind_orders_02.json  9103 2025-04-21 01:31:03.085706472\n",
       "2  northwind_orders_03.json  9008 2025-04-21 01:31:03.085754871"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_file_info(orders_stream_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725f2bda-d78e-4731-9d4e-10d75d3607ba",
   "metadata": {},
   "source": [
    "#### 6.2. Create the Bronze Layer: Stage <span style=\"color:darkred\">Orders Fact table</span> Data\n",
    "##### 6.2.1. Read \"Raw\" JSON file data into a Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fe375157-dfad-4442-8563-0a05cacecb55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orders_bronze = (\n",
    "    spark.readStream \\\n",
    "    .option(\"schemaLocation\", orders_output_bronze) \\\n",
    "    .option(\"maxFilesPerTrigger\", 1) \\\n",
    "    .option(\"multiLine\", \"true\") \\\n",
    "    .json(orders_stream_dir)\n",
    ")\n",
    "\n",
    "df_orders_bronze.isStreaming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e94035a-3bc4-4ba2-abf5-63ca89b4e0f7",
   "metadata": {},
   "source": [
    "##### 6.2.2. Write the Streaming Data to a Parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3cd60124-791d-4df3-99eb-a5943c5b3f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_checkpoint_bronze = os.path.join(orders_output_bronze, '_checkpoint')\n",
    "\n",
    "orders_bronze_query = (\n",
    "    df_orders_bronze\n",
    "    # Add Current Timestamp and Input Filename columns for Traceability\n",
    "    .withColumn(\"receipt_time\", current_timestamp())\n",
    "    .withColumn(\"source_file\", input_file_name())\n",
    "    \n",
    "    .writeStream \\\n",
    "    .format(\"parquet\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .queryName(\"orders_bronze\")\n",
    "    .trigger(availableNow = True) \\\n",
    "    .option(\"checkpointLocation\", orders_checkpoint_bronze) \\\n",
    "    .option(\"compression\", \"snappy\") \\\n",
    "    .start(orders_output_bronze)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45b461d-1d9c-4233-aae9-cae37539c0ba",
   "metadata": {},
   "source": [
    "##### 6.2.3. Unit Test: Implement Query Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "299479ba-fb32-4260-8585-14f9c47b1b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query ID: 1275be83-3562-4862-8f69-ad7dcb9b1bd0\n",
      "Query Name: orders_bronze\n",
      "Query Status: {'message': 'Stopped', 'isDataAvailable': False, 'isTriggerActive': False}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Query ID: {orders_bronze_query.id}\")\n",
    "print(f\"Query Name: {orders_bronze_query.name}\")\n",
    "print(f\"Query Status: {orders_bronze_query.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bc62d72c-f857-43c0-8c37-716ef3501064",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_bronze_query.awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1baf025-d6fd-4b69-89d2-dd89c3205496",
   "metadata": {},
   "source": [
    "#### 6.3. Create the Silver Layer: Integrate \"Cold-path\" Data & Make Transformations\n",
    "##### 6.3.1. Prepare Role-Playing Dimension Primary and Business Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "28b1f33c-0ebd-4156-9f14-e8588cab2c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dim_order_date = df_dim_date.select(col(\"date_key\").alias(\"order_date_key\"), col(\"full_date\").alias(\"order_full_date\"))\n",
    "df_dim_paid_date = df_dim_date.select(col(\"date_key\").alias(\"paid_date_key\"), col(\"full_date\").alias(\"paid_full_date\"))\n",
    "df_dim_shipped_date = df_dim_date.select(col(\"date_key\").alias(\"shipped_date_key\"), col(\"full_date\").alias(\"shipped_full_date\"))\n",
    "df_dim_shippers = df_dim_shippers.withColumnRenamed(\"shipper_id\", \"shipper_no\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7b0437-66a7-4386-9084-4594faab6df0",
   "metadata": {},
   "source": [
    "##### 6.3.2. Define Silver Query to Join Streaming with Batch Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1f8ea470-0cc3-4530-99de-8cf5beae64cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orders_silver = spark.readStream.format(\"parquet\").load(orders_output_bronze) \\\n",
    "    .join(df_dim_customers, \"customer_id\") \\\n",
    "    .join(df_dim_employees, \"employee_id\") \\\n",
    "    .join(df_dim_products, \"product_id\") \\\n",
    "    .join(df_dim_shippers, df_dim_shippers.shipper_no == col(\"shipper_id\").cast(IntegerType()), \"left_outer\") \\\n",
    "    .join(df_dim_order_date, df_dim_order_date.order_full_date.cast(DateType()) == col(\"order_date\").cast(DateType()), \"inner\") \\\n",
    "    .join(df_dim_shipped_date, df_dim_shipped_date.shipped_full_date.cast(DateType()) == col(\"shipped_date\").cast(DateType()), \"left_outer\") \\\n",
    "    .join(df_dim_paid_date, df_dim_paid_date.paid_full_date.cast(DateType()) == col(\"paid_date\").cast(DateType()), \"left_outer\") \\\n",
    "    .select(col(\"order_id\").cast(LongType()), \\\n",
    "            col(\"order_detail_id\").cast(LongType()), \\\n",
    "            df_dim_customers.customer_key.cast(LongType()), \\\n",
    "            df_dim_employees.employee_key.cast(LongType()), \\\n",
    "            df_dim_products.product_key.cast(LongType()), \\\n",
    "            df_dim_shippers.shipper_key.cast(IntegerType()), \\\n",
    "            df_dim_order_date.order_date_key.cast(LongType()), \\\n",
    "            df_dim_paid_date.paid_date_key.cast(LongType()), \\\n",
    "            df_dim_shipped_date.shipped_date_key.cast(LongType()), \\\n",
    "            col(\"quantity\"), \\\n",
    "            col(\"unit_price\"), \\\n",
    "            col(\"discount\"), \\\n",
    "            col(\"shipping_fee\"), \\\n",
    "            col(\"taxes\"), \\\n",
    "            col(\"tax_rate\"), \\\n",
    "            col(\"payment_type\"), \\\n",
    "            col(\"order_status\"), \\\n",
    "            col(\"order_details_status\") \\\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cce36782-37f7-4a7a-baf8-bc6c9d7e647d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orders_silver.isStreaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "adcb25db-964b-41ed-bfc8-9ca633c219b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: long (nullable = true)\n",
      " |-- order_detail_id: long (nullable = true)\n",
      " |-- customer_key: long (nullable = false)\n",
      " |-- employee_key: long (nullable = false)\n",
      " |-- product_key: long (nullable = false)\n",
      " |-- shipper_key: integer (nullable = true)\n",
      " |-- order_date_key: long (nullable = true)\n",
      " |-- paid_date_key: long (nullable = true)\n",
      " |-- shipped_date_key: long (nullable = true)\n",
      " |-- quantity: double (nullable = true)\n",
      " |-- unit_price: double (nullable = true)\n",
      " |-- discount: long (nullable = true)\n",
      " |-- shipping_fee: double (nullable = true)\n",
      " |-- taxes: double (nullable = true)\n",
      " |-- tax_rate: long (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      " |-- order_details_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_orders_silver.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6c9fd4-c595-4c38-adb3-c5a3a1f13f53",
   "metadata": {},
   "source": [
    "##### 6.3.3. Write the Transformed Streaming data to the Data Lakehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "145b60d0-0985-4641-822a-7e7995ce0785",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_checkpoint_silver = os.path.join(orders_output_silver, '_checkpoint')\n",
    "\n",
    "orders_silver_query = (\n",
    "    df_orders_silver.writeStream \\\n",
    "    .format(\"parquet\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .queryName(\"orders_silver\")\n",
    "    .trigger(availableNow = True) \\\n",
    "    .option(\"checkpointLocation\", orders_checkpoint_silver) \\\n",
    "    .option(\"compression\", \"snappy\") \\\n",
    "    .start(orders_output_silver)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a6c445-16dd-4752-9e46-6ba7e9cef121",
   "metadata": {},
   "source": [
    "##### 6.3.4. Unit Test: Implement Query Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ea1e7be2-fea6-4578-9237-344983c52111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query ID: c2168002-5a49-4ce3-b389-c6a38bd8ff77\n",
      "Query Name: orders_silver\n",
      "Query Status: {'message': 'Stopped', 'isDataAvailable': False, 'isTriggerActive': False}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Query ID: {orders_silver_query.id}\")\n",
    "print(f\"Query Name: {orders_silver_query.name}\")\n",
    "print(f\"Query Status: {orders_silver_query.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1493145c-19b3-4446-84e1-b9a37ecf2010",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_silver_query.awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb44a5a-b470-4928-bc73-b5ed9ff8da74",
   "metadata": {},
   "source": [
    "#### 6.4. Create Gold Layer: Perform Aggregations\n",
    "##### 6.4.1. Define a Query to Create a Business Report\n",
    "Create a new Gold table using the PySpark API. The table should include the number of Products sold per Category each Month. The results should include The Month, Product Category and Number of Products sold, sorted by the month number when the orders were placed: e.g., January, February, March."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2b0bb272-a7c1-4f2a-a3d9-5ee5fd6f454a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orders_by_product_category_gold = spark.readStream.format(\"parquet\").load(orders_output_silver) \\\n",
    ".join(df_dim_products, \"product_key\") \\\n",
    ".join(df_dim_date, df_dim_date.date_key.cast(IntegerType()) == col(\"order_date_key\").cast(IntegerType())) \\\n",
    ".groupBy(\"month_of_year\", \"category\", \"month_name\") \\\n",
    ".agg(count(\"product_key\").alias(\"product_count\")) \\\n",
    ".orderBy(asc(\"month_of_year\"), desc(\"product_count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "36930416-660d-4814-a66c-a08d732ba921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- month_of_year: byte (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- month_name: string (nullable = true)\n",
      " |-- product_count: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_orders_by_product_category_gold.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb8abc8-c889-4ed2-8d37-f15bb1c27ffb",
   "metadata": {},
   "source": [
    "##### 6.4.2. Write the Streaming data to a Parquet File in \"Complete\" mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0619456b-2217-4a27-b9cf-5d764610a6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_gold_query = (\n",
    "    df_orders_by_product_category_gold.writeStream \\\n",
    "    .format(\"memory\") \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .queryName(\"fact_orders_by_product_category\")\n",
    "    .start()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e88c1d0b-8341-4c5a-9970-c7e2f444feca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The stream has processed 1 batchs\n"
     ]
    }
   ],
   "source": [
    "wait_until_stream_is_ready(orders_gold_query, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b627bd3d-d17b-4ab2-b62a-1b988d10a7c6",
   "metadata": {},
   "source": [
    "##### 6.4.3. Query the Gold Data from Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c1d4cf7a-de59-4596-a8af-0e84790d7b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- month_of_year: byte (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- month_name: string (nullable = true)\n",
      " |-- product_count: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fact_orders_by_product_category = spark.sql(\"SELECT * FROM fact_orders_by_product_category\")\n",
    "df_fact_orders_by_product_category.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7c34a4-74ab-45cb-b096-fdd860a00012",
   "metadata": {},
   "source": [
    "##### 6.4.4 Create the Final Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "83ba5a02-ea03-4f9e-99d8-f50327779467",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fact_orders_by_product_category_gold_final = df_fact_orders_by_product_category \\\n",
    ".select(col(\"month_name\").alias(\"Month\"), \\\n",
    "        col(\"category\").alias(\"Product Category\"), \\\n",
    "        col(\"product_count\").alias(\"Product Count\")) \\\n",
    ".orderBy(asc(\"month_of_year\"), desc(\"Product Count\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c010c836-3593-4ff5-afb1-f5b29798f3dd",
   "metadata": {},
   "source": [
    "##### 6.4.5. Load the Final Results into a New Table and Display the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3f7ba782-5dca-4030-b386-04e8f7c5e249",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Product Category</th>\n",
       "      <th>Product Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>March</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>March</td>\n",
       "      <td>Sauces</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>March</td>\n",
       "      <td>Dried Fruit &amp; Nuts</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>March</td>\n",
       "      <td>Jams, Preserves</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>March</td>\n",
       "      <td>Candy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>March</td>\n",
       "      <td>Condiments</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>March</td>\n",
       "      <td>Baked Goods &amp; Mixes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>January</td>\n",
       "      <td>Dried Fruit &amp; Nuts</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>January</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>January</td>\n",
       "      <td>Baked Goods &amp; Mixes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>February</td>\n",
       "      <td>Candy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>February</td>\n",
       "      <td>Soups</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>February</td>\n",
       "      <td>Baked Goods &amp; Mixes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>June</td>\n",
       "      <td>Dried Fruit &amp; Nuts</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>June</td>\n",
       "      <td>Candy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>June</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>June</td>\n",
       "      <td>Condiments</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>June</td>\n",
       "      <td>Soups</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>June</td>\n",
       "      <td>Canned Fruit &amp; Vegetables</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>June</td>\n",
       "      <td>Jams, Preserves</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>April</td>\n",
       "      <td>Baked Goods &amp; Mixes</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>April</td>\n",
       "      <td>Sauces</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>April</td>\n",
       "      <td>Dairy products</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>April</td>\n",
       "      <td>Soups</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>April</td>\n",
       "      <td>Canned Meat</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>May</td>\n",
       "      <td>Dried Fruit &amp; Nuts</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>May</td>\n",
       "      <td>Canned Meat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>May</td>\n",
       "      <td>Sauces</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>April</td>\n",
       "      <td>Candy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>April</td>\n",
       "      <td>Condiments</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>April</td>\n",
       "      <td>Grains</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>April</td>\n",
       "      <td>Oil</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>April</td>\n",
       "      <td>Jams, Preserves</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>April</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>April</td>\n",
       "      <td>Pasta</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Month           Product Category  Product Count\n",
       "0   March                       Beverages              7\n",
       "1   March                          Sauces              1\n",
       "2   March              Dried Fruit & Nuts              1\n",
       "3   March                 Jams, Preserves              1\n",
       "4   March                           Candy              1\n",
       "5   March                      Condiments              1\n",
       "6   March             Baked Goods & Mixes              1\n",
       "7   January            Dried Fruit & Nuts              4\n",
       "8   January                     Beverages              3\n",
       "9   January           Baked Goods & Mixes              1\n",
       "10  February                        Candy              1\n",
       "11  February                        Soups              1\n",
       "12  February          Baked Goods & Mixes              1\n",
       "13  June               Dried Fruit & Nuts              2\n",
       "14  June                            Candy              2\n",
       "15  June                        Beverages              1\n",
       "16  June                       Condiments              1\n",
       "17  June                            Soups              1\n",
       "18  June        Canned Fruit & Vegetables              1\n",
       "19  June                  Jams, Preserves              1\n",
       "20  April             Baked Goods & Mixes              2\n",
       "21  April                          Sauces              2\n",
       "22  April                  Dairy products              2\n",
       "23  April                           Soups              2\n",
       "24  April                     Canned Meat              2\n",
       "25  May                Dried Fruit & Nuts              2\n",
       "26  May                       Canned Meat              1\n",
       "27  May                            Sauces              1\n",
       "28  April                           Candy              1\n",
       "29  April                      Condiments              1\n",
       "30  April                          Grains              1\n",
       "31  April                             Oil              1\n",
       "32  April                 Jams, Preserves              1\n",
       "33  April                       Beverages              3\n",
       "34  April                           Pasta              3"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fact_orders_by_product_category_gold_final.write.saveAsTable(f\"{dest_database}.fact_orders_by_product_category\", mode=\"overwrite\")\n",
    "spark.sql(f\"SELECT * FROM {dest_database}.fact_orders_by_product_category\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be545e39-4352-4688-b7c1-92097acd2e88",
   "metadata": {},
   "source": [
    "### 7.0. Use PySpark Structured Streaming to Process (Hot Path) <span style=\"color:darkred\">Inventory Transactions</span> Fact Data\n",
    "#### 7.1. Verify the location of the source data files on the file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cbb671dd-1607-41d4-8ebd-e1edce43311a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>size</th>\n",
       "      <th>modification_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>northwind_inventory_transactions_01.json</td>\n",
       "      <td>7656</td>\n",
       "      <td>2025-04-21 01:31:03.085403919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>northwind_inventory_transactions_02.json</td>\n",
       "      <td>7590</td>\n",
       "      <td>2025-04-21 01:31:03.085463047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>northwind_inventory_transactions_03.json</td>\n",
       "      <td>7587</td>\n",
       "      <td>2025-04-21 01:31:03.085515976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       name  size  \\\n",
       "0  northwind_inventory_transactions_01.json  7656   \n",
       "1  northwind_inventory_transactions_02.json  7590   \n",
       "2  northwind_inventory_transactions_03.json  7587   \n",
       "\n",
       "              modification_time  \n",
       "0 2025-04-21 01:31:03.085403919  \n",
       "1 2025-04-21 01:31:03.085463047  \n",
       "2 2025-04-21 01:31:03.085515976  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_file_info(inventory_trans_stream_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4029fc9f-6ed7-48f6-a347-0245926a542f",
   "metadata": {},
   "source": [
    "#### 7.2. Create the Bronze Layer: Stage <span style=\"color:darkred\">Inventory Transactions Fact table</span> Data\n",
    "##### 7.2.1. Read \"Raw\" JSON file data into a Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2f047ae2-f893-4dea-884b-f2e5ebdd5253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inventory_trans_bronze = (\n",
    "    spark.readStream \\\n",
    "    #TODO: load data from 'inventory_trans_stream_dir'\n",
    "    .option(\"maxFilesPerTrigger\", 1)\n",
    "    .option(\"multiLine\", \"true\")\n",
    "    .json(inventory_trans_stream_dir)\n",
    "    \n",
    ")\n",
    "\n",
    "df_inventory_trans_bronze.isStreaming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739e693f-7dcb-4e8d-ac6a-dd12b19c32ad",
   "metadata": {},
   "source": [
    "##### 7.2.2. Write the Streaming Data to a Parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3598e1e1-3c23-4421-8cd9-da6c93133cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory_trans_checkpoint_bronze = os.path.join(inventory_trans_output_bronze, '_checkpoint')\n",
    "\n",
    "inventory_trans_bronze_query = (\n",
    "    df_inventory_trans_bronze\n",
    "    # TODO: Add Current Timestamp and Input Filename columns for Traceability\n",
    "    # TODO: writeStream to 'inventory_trans_output_bronze' in 'append' mode\n",
    "    .withColumn(\"receipt_time\", current_timestamp())\n",
    "    .withColumn(\"source_file\", input_file_name())\n",
    "    .writeStream\n",
    "    .format(\"parquet\")\n",
    "    .outputMode(\"append\")\n",
    "    .queryName(\"inventory_trans_bronze\")\n",
    "    .trigger(availableNow=True)\n",
    "    .option(\"checkpointLocation\", inventory_trans_checkpoint_bronze)\n",
    "    .option(\"compression\", \"snappy\")\n",
    "    .start(inventory_trans_output_bronze)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb998485-8a0f-4ba1-b51c-03836b36f1af",
   "metadata": {},
   "source": [
    "##### 7.2.3. Unit Test: Implement Query Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0b12a2c9-d8fb-4df0-b146-46ce1a1b1eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query ID: 66d7e64d-f4c5-409a-ac28-1af36c504f2e\n",
      "Query Name: inventory_trans_bronze\n",
      "Query Status: {'message': 'Stopped', 'isDataAvailable': False, 'isTriggerActive': False}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Query ID: {inventory_trans_bronze_query.id}\")\n",
    "print(f\"Query Name: {inventory_trans_bronze_query.name}\")\n",
    "print(f\"Query Status: {inventory_trans_bronze_query.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "095d3f5e-c44e-47f2-9f59-cffcd37ad64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory_trans_bronze_query.awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8794a1-1b49-4c01-a87c-8b84cd79c30e",
   "metadata": {},
   "source": [
    "#### 7.3. Create the Silver Layer: Integrate \"Cold-path\" Data & Make Transformations\n",
    "##### 7.3.1. Prepare Role-Playing Dimension Primary and Business Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "28ce86a8-af37-487c-8b5b-7e70b50cd550",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dim_created_date = df_dim_date.selectExpr(\"date_key as created_date_key\", \"full_date as created_full_date\") #TODO: Copy df_dim_date and rename 'date_key' and 'full_date' columns.\n",
    "df_dim_modified_date = df_dim_date.selectExpr(\"date_key as modified_date_key\", \"full_date as modified_full_date\") #TODO: Copy df_dim_date and rename 'date_key' and 'full_date' columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f7397e-1b73-4ca3-b65c-8fa92063676b",
   "metadata": {},
   "source": [
    "##### 7.3.2. Define Silver Query to Join Streaming with Batch Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2bb0721a-016e-4b46-af06-e63b26fc0629",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inventory_trans_silver = (spark.readStream.format(\"parquet\").load(inventory_trans_output_bronze) \\\n",
    "    # .join to the dim_products dimension\n",
    "    # .join to the dim_created_date dimension\n",
    "    # .join to the dim_created_date\n",
    "    # .join to the dim_modified_date dimension\n",
    "    # .select() the appropriate columns\n",
    "    .join(df_dim_products.select(\"product_id\", \"product_key\"), on=\"product_id\", how=\"inner\")\n",
    "    .join(df_dim_created_date, expr(\"created_full_date = CAST(transaction_created_date AS DATE)\"), \"inner\")\n",
    "    .join(df_dim_modified_date, expr(\"modified_full_date = CAST(transaction_modified_date AS DATE)\"), \"left_outer\")\n",
    "    .selectExpr(\n",
    "        \"inventory_transaction_id\",\n",
    "        \"product_key\",\n",
    "        \"transaction_type\",\n",
    "        \"quantity\",\n",
    "        \"created_date_key\",\n",
    "        \"modified_date_key\",\n",
    "        \"receipt_time\",\n",
    "        \"source_file\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "62550a69-a8b1-40ea-8f99-9e2aeb864d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inventory_trans_silver.isStreaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6e4d7610-93db-4864-99ce-b2eb6a3ff27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- inventory_transaction_id: long (nullable = true)\n",
      " |-- product_key: integer (nullable = false)\n",
      " |-- transaction_type: string (nullable = true)\n",
      " |-- quantity: long (nullable = true)\n",
      " |-- created_date_key: integer (nullable = true)\n",
      " |-- modified_date_key: integer (nullable = true)\n",
      " |-- receipt_time: timestamp (nullable = true)\n",
      " |-- source_file: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_inventory_trans_silver.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8748cf85-83f5-437c-8888-63cdbc82dfce",
   "metadata": {},
   "source": [
    "##### 7.3.3. Write the Transformed Streaming data to the Data Lakehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "264ecda0-0f45-41fe-98ad-1f183034743e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory_trans_checkpoint_silver = os.path.join(inventory_trans_output_silver, '_checkpoint')\n",
    "\n",
    "inventory_trans_silver_query = (\n",
    "    df_inventory_trans_silver.writeStream \\\n",
    "    # TODO: writeStream, in 'parquet' format, to 'inventory_trans_output_silver' in 'append' mode\n",
    "    .format(\"parquet\")\n",
    "    .outputMode(\"append\")\n",
    "    .queryName(\"inventory_trans_silver\")\n",
    "    .trigger(availableNow=True)\n",
    "    .option(\"checkpointLocation\", inventory_trans_checkpoint_silver)\n",
    "    .option(\"compression\", \"snappy\")\n",
    "    .start(inventory_trans_output_silver)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9465503-b7e8-45bd-9f7a-eff4487470ed",
   "metadata": {},
   "source": [
    "##### 7.3.4. Unit Test: Implement Query Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ff5d0584-5ac9-4ba8-adbd-9a240313460c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query ID: fb0c5b6f-8aff-45d6-80cb-46b3ad4beff1\n",
      "Query Name: inventory_trans_silver\n",
      "Query Status: {'message': 'Stopped', 'isDataAvailable': False, 'isTriggerActive': False}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Query ID: {inventory_trans_silver_query.id}\")\n",
    "print(f\"Query Name: {inventory_trans_silver_query.name}\")\n",
    "print(f\"Query Status: {inventory_trans_silver_query.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fb5ebfb9-11f5-462f-a8dd-e8d273a78be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory_trans_silver_query.awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef4e324-0c76-4cab-9eb2-e87148ba92b8",
   "metadata": {},
   "source": [
    "#### 7.4. Create Gold Layer: Perform Aggregations\n",
    "##### 7.4.1. Define a Query to Create a Business Report\n",
    "Create a new Gold table using the PySpark API. The table should include the total quantity (total quantity) of the inventory transactions placed per Product. Include the Inventory Transaction Type, and the Product Name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "659f7927-50a2-46c2-9b5e-7081e1f3e8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fact_inventory_trans_by_product_gold = (spark.readStream.format(\"parquet\").load(inventory_trans_output_silver) \\\n",
    "    #.join to the df_dim_products dimension\n",
    "    #.join to the df_dim_date dimension on the 'created_date_key'\n",
    "    # group by the 'calendar_quarter', 'transaction_type', and 'product_name columns\n",
    "    # sum the 'quantity' column to create the 'Total Quantity' column\n",
    "    # order by the 'Total Quantity' column\n",
    "    .join(df_dim_products.select(\"product_key\", \"product_name\"), on=\"product_key\")\n",
    "    .join(df_dim_date.selectExpr(\"date_key as created_date_key\", \"calendar_quarter\"), on=\"created_date_key\")\n",
    "    .groupBy(\"calendar_quarter\", \"transaction_type\", \"product_name\")\n",
    "    .agg(sum(\"quantity\").alias(\"Total_Quantity\"))\n",
    "    .orderBy(col(\"Total_Quantity\").desc())\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf05ceb-f4d6-44d0-b8e9-600a99b15c2d",
   "metadata": {},
   "source": [
    "##### 7.4.2. Write the Streaming data to Memory in \"Complete\" mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3b3d116c-dc4a-42e9-bb0f-4cb7ba4f648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory_trans_gold_query = (\n",
    "    df_fact_inventory_trans_by_product_gold.writeStream \\\n",
    "    # create the new \"fact_inventory_trans_by_product\" query\n",
    "    .format(\"memory\")\n",
    "    .outputMode(\"complete\")\n",
    "    .queryName(\"fact_inventory_trans_by_product\")\n",
    "    .start()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5f2067cb-8161-431a-aa44-a64aeb4edbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The stream has processed 1 batchs\n"
     ]
    }
   ],
   "source": [
    "wait_until_stream_is_ready(inventory_trans_gold_query, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400a5435-0180-4155-a4db-3d5ded849b13",
   "metadata": {},
   "source": [
    "##### 7.4.3. Query the Gold Data from Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "93253cef-fb6a-4fa4-b622-db2ff1a13676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- calendar_quarter: byte (nullable = true)\n",
      " |-- transaction_type: string (nullable = true)\n",
      " |-- product_name: string (nullable = true)\n",
      " |-- Total_Quantity: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fact_inventory_trans_by_product = spark.sql(\"SELECT * FROM fact_inventory_trans_by_product\")\n",
    "df_fact_inventory_trans_by_product.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054ebf94-58fe-4851-9399-c1f41b80c556",
   "metadata": {},
   "source": [
    "##### 7.4.4 Create the Final Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a4582066-5790-4931-beb7-c90f03ded4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fact_inventory_trans_by_product_gold_final = (df_fact_inventory_trans_by_product \\\n",
    "    # .select() the 'calendar_quarter' column as 'Quarter Created',\n",
    "    # 'transaction_type' as 'Transaction', 'product_name' as 'Product', and 'Total Quantity'\n",
    "    # ordered by 'Total Quantity'.\n",
    "    .selectExpr(\n",
    "        \"calendar_quarter as Quarter_Created\",\n",
    "        \"transaction_type as Transaction\",\n",
    "        \"product_name as Product\",\n",
    "        \"Total_Quantity\"\n",
    "    )\n",
    "    .orderBy(col(\"Total_Quantity\").desc())\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dfd0b7-bba2-40f5-8efd-b8b47961da38",
   "metadata": {},
   "source": [
    "##### 7.4.5. Load the Final Results into a New Table and Display the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "252eec1c-abe8-439f-bc4c-2ec181a48baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter_Created</th>\n",
       "      <th>Transaction</th>\n",
       "      <th>Product</th>\n",
       "      <th>Total_Quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Sold</td>\n",
       "      <td>Northwind Traders Clam Chowder</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Purchased</td>\n",
       "      <td>Northwind Traders Mustard</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Purchased</td>\n",
       "      <td>Northwind Traders Clam Chowder</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Sold</td>\n",
       "      <td>Northwind Traders Chocolate Biscuits Mix</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Purchased</td>\n",
       "      <td>Northwind Traders Mozzarella</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1</td>\n",
       "      <td>Sold</td>\n",
       "      <td>Northwind Traders Green Tea</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1</td>\n",
       "      <td>Purchased</td>\n",
       "      <td>Northwind Traders Chocolate</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2</td>\n",
       "      <td>Sold</td>\n",
       "      <td>Northwind Traders Cajun Seasoning</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2</td>\n",
       "      <td>Sold</td>\n",
       "      <td>Northwind Traders Dried Apples</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2</td>\n",
       "      <td>Sold</td>\n",
       "      <td>Northwind Traders Dried Pears</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Quarter_Created Transaction                                   Product  \\\n",
       "0                 2        Sold            Northwind Traders Clam Chowder   \n",
       "1                 1   Purchased                 Northwind Traders Mustard   \n",
       "2                 2   Purchased            Northwind Traders Clam Chowder   \n",
       "3                 1        Sold  Northwind Traders Chocolate Biscuits Mix   \n",
       "4                 2   Purchased              Northwind Traders Mozzarella   \n",
       "..              ...         ...                                       ...   \n",
       "72                1        Sold               Northwind Traders Green Tea   \n",
       "73                1   Purchased               Northwind Traders Chocolate   \n",
       "74                2        Sold         Northwind Traders Cajun Seasoning   \n",
       "75                2        Sold            Northwind Traders Dried Apples   \n",
       "76                2        Sold             Northwind Traders Dried Pears   \n",
       "\n",
       "    Total_Quantity  \n",
       "0               60  \n",
       "1               60  \n",
       "2               50  \n",
       "3               50  \n",
       "4               50  \n",
       "..             ...  \n",
       "72             200  \n",
       "73             200  \n",
       "74              30  \n",
       "75              30  \n",
       "76              30  \n",
       "\n",
       "[77 rows x 4 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fact_inventory_trans_by_product_gold_final.write.saveAsTable(f\"{dest_database}.fact_inventory_trans_by_product\", mode=\"overwrite\")\n",
    "spark.sql(f\"SELECT * FROM {dest_database}.fact_inventory_trans_by_product\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b2dcb2-82e3-4a30-b04d-b06d92044735",
   "metadata": {},
   "source": [
    "### 8.0. Use PySpark Structured Streaming to Process (Hot Path) <span style=\"color:darkred\">Purchase Orders</span> Fact Data\n",
    "#### 8.1. Verify the location of the source data files on the file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1b074ee6-767a-426e-9ff0-466f50f2ed64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>size</th>\n",
       "      <th>modification_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>northwind_purchase_orders_01.json</td>\n",
       "      <td>11245</td>\n",
       "      <td>2025-04-21 01:31:03.085878849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>northwind_purchase_orders_02.json</td>\n",
       "      <td>10651</td>\n",
       "      <td>2025-04-21 01:31:03.085936785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>northwind_purchase_orders_03.json</td>\n",
       "      <td>10471</td>\n",
       "      <td>2025-04-21 01:31:03.085988998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                name   size             modification_time\n",
       "0  northwind_purchase_orders_01.json  11245 2025-04-21 01:31:03.085878849\n",
       "1  northwind_purchase_orders_02.json  10651 2025-04-21 01:31:03.085936785\n",
       "2  northwind_purchase_orders_03.json  10471 2025-04-21 01:31:03.085988998"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_file_info(purchase_orders_stream_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1743fafa-155b-46be-b28a-1d4b31dd44e3",
   "metadata": {},
   "source": [
    "#### 8.2. Create the Bronze Layer: Stage <span style=\"color:darkred\">Purchase Orders Fact table</span> Data\n",
    "##### 8.2.1. Read \"Raw\" JSON file data into a Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b4945ea6-4215-4ccf-9d49-628f3848fbd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_purchase_orders_bronze = (\n",
    "    spark.readStream \\\n",
    "    # TODO: load data from 'purchase_orders_stream_dir'\n",
    "    .option(\"multiLine\", \"true\")\n",
    "    .schema(\"po_number STRING, po_detail_id STRING, product_id LONG, supplier_id LONG, submitted_by INT, created_by INT, approved_by INT, submitted_date STRING, creation_date STRING, approved_date STRING, date_received STRING, po_detail_quantity INT, po_detail_unit_cost DOUBLE, list_price DOUBLE\")\n",
    "    .json(purchase_orders_stream_dir)\n",
    ")\n",
    "\n",
    "df_purchase_orders_bronze.isStreaming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e5f3a9-fcc2-485c-96b8-c62ef8bee2cb",
   "metadata": {},
   "source": [
    "##### 8.2.2. Write the Streaming Data to a Parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "740a81c5-ffb0-4158-8644-67b1e58c55da",
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase_orders_checkpoint_bronze = os.path.join(purchase_orders_output_bronze, '_checkpoint')\n",
    "\n",
    "purchase_orders_bronze_query = (\n",
    "    df_purchase_orders_bronze\n",
    "    # TODO: Add Current Timestamp and Input Filename columns for Traceability\n",
    "    # TODO: writeStream to 'purchase_orders_output_bronze' in 'append' mode\n",
    "    .withColumnRenamed(\"list_price\", \"bronze_list_price\")\n",
    "    .withColumn(\"receipt_time\", current_timestamp())\n",
    "    .withColumn(\"source_file\", input_file_name())\n",
    "    .writeStream\n",
    "    .format(\"parquet\")\n",
    "    .outputMode(\"append\")\n",
    "    .queryName(\"purchase_orders_bronze\")\n",
    "    .trigger(availableNow=True)\n",
    "    .option(\"checkpointLocation\", purchase_orders_checkpoint_bronze)\n",
    "    .option(\"compression\", \"snappy\")\n",
    "    .start(purchase_orders_output_bronze)\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be7eecc-e366-4c42-8ce2-139124e43fbf",
   "metadata": {},
   "source": [
    "##### 8.2.3. Unit Test: Implement Query Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0bd8e3da-70f4-4132-942e-6b494cd48998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query ID: 88844c1f-1eef-44da-9770-c4a54376846a\n",
      "Query Name: purchase_orders_bronze\n",
      "Query Status: {'message': 'Stopped', 'isDataAvailable': False, 'isTriggerActive': False}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Query ID: {purchase_orders_bronze_query.id}\")\n",
    "print(f\"Query Name: {purchase_orders_bronze_query.name}\")\n",
    "print(f\"Query Status: {purchase_orders_bronze_query.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "aac5d2ab-d1fd-4900-a14a-c0605ac58f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase_orders_bronze_query.awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c242a939-e121-4d6c-83a5-70817bc6d1b8",
   "metadata": {},
   "source": [
    "#### 8.3. Create the Silver Layer: Integrate \"Cold-path\" Data & Make Transformations\n",
    "##### 8.3.1. Prepare Role-Playing Dimension Primary and Business Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e74d5b82-da69-471f-a362-21940382adc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dim_created_by = df_dim_employees.selectExpr(\"employee_key as created_by_key\", \"employee_id as created_by_id\")\n",
    "df_dim_approved_by = df_dim_employees.selectExpr(\"employee_key as approved_by_key\", \"employee_id as approved_by_id\")\n",
    "df_dim_submitted_by = df_dim_employees.selectExpr(\"employee_key as submitted_by_key\", \"employee_id as submitted_by_id\")\n",
    "\n",
    "df_dim_submitted_date = df_dim_date.selectExpr(\"date_key as submitted_date_key\", \"full_date as submitted_full_date\")\n",
    "df_dim_creation_date = df_dim_date.selectExpr(\"date_key as creation_date_key\", \"full_date as creation_full_date\")\n",
    "df_dim_approved_date = df_dim_date.selectExpr(\"date_key as approved_date_key\", \"full_date as approved_full_date\")\n",
    "df_dim_date_received = df_dim_date.selectExpr(\"date_key as date_received_key\", \"full_date as date_received_full_date\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9a6681-5eb1-4c45-89b2-fd125a9eb6a0",
   "metadata": {},
   "source": [
    "##### 8.3.2. Define Silver Query to Join Streaming with Batch Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "78a807bc-186d-44c0-b181-01c2f6c6e1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_purchase_orders_silver = (spark.readStream.format(\"parquet\").load(purchase_orders_output_bronze) \\\n",
    "    # .join 'inner' to the df_dim_products dimension\n",
    "    # .join 'inner' to the df_dim_suppliers\n",
    "    # .join 'left_outer' to the df_dim_created_by dimension\n",
    "    # .join 'left_outer' to the df_dim_approved_by dimension\n",
    "    # .join 'left_outer' to the df_dim_submitted_by dimension\n",
    "    # .join 'inner' to the df_dim_submitted_date dimension\n",
    "    # .join 'inner' to the df_dim_creation_date\n",
    "    # .join 'left_outer' to the df_dim_approved_date dimension\n",
    "    # .join 'left_outer' to the df_dim_date_received dimension\n",
    "    # .select() the appropriate columns from the 'purchase orders bronze' stream\n",
    "  \n",
    "from pyspark.sql.functions import col, expr\n",
    "\n",
    "df_purchase_orders_bronze = (\n",
    "    spark.readStream\n",
    "        .format(\"parquet\")\n",
    "        .load(purchase_orders_output_bronze)\n",
    "        .withColumnRenamed(\"list_price\", \"bronze_list_price\")\n",
    ")\n",
    "\n",
    "df_purchase_orders_silver = (\n",
    "    df_purchase_orders_bronze\n",
    "        .join(df_dim_products, \"product_id\", \"inner\")\n",
    "        .join(df_dim_suppliers, \"supplier_id\", \"inner\")\n",
    "        .join(df_dim_created_by, df_dim_created_by.created_by_id == col(\"created_by\"), \"left_outer\")\n",
    "        .join(df_dim_approved_by, df_dim_approved_by.approved_by_id == col(\"approved_by\"), \"left_outer\")\n",
    "        .join(df_dim_submitted_by, df_dim_submitted_by.submitted_by_id == col(\"submitted_by\"), \"left_outer\")\n",
    "        .join(df_dim_submitted_date, expr(\"CAST(submitted_date AS DATE) = submitted_full_date\"), \"inner\")\n",
    "        .join(df_dim_creation_date, expr(\"CAST(creation_date AS DATE) = creation_full_date\"), \"inner\")\n",
    "        .join(df_dim_approved_date, expr(\"CAST(approved_date AS DATE) = approved_full_date\"), \"left_outer\")\n",
    "        .join(df_dim_date_received, expr(\"CAST(date_received AS DATE) = date_received_full_date\"), \"left_outer\")\n",
    "        .selectExpr(\n",
    "            \"po_number\",\n",
    "            \"po_detail_id\",\n",
    "            \"product_key\",\n",
    "            \"supplier_key\",\n",
    "            \"created_by_key\",\n",
    "            \"approved_by_key\",\n",
    "            \"submitted_by_key\",\n",
    "            \"creation_date_key\",\n",
    "            \"approved_date_key\",\n",
    "            \"submitted_date_key\",\n",
    "            \"date_received_key\",\n",
    "            \"po_detail_quantity\",\n",
    "            \"po_detail_unit_cost\",\n",
    "            \"list_price as product_list_price\",\n",
    "            \"bronze_list_price\",\n",
    "            \"receipt_time\",\n",
    "            \"source_file\"\n",
    "        )\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e1ffacdc-813d-49db-bc17-5d510371545b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_purchase_orders_silver.isStreaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "7c7daf6d-3121-4dd7-9e01-4b51397b69cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- po_number: string (nullable = true)\n",
      " |-- po_detail_id: string (nullable = true)\n",
      " |-- product_key: integer (nullable = false)\n",
      " |-- supplier_key: integer (nullable = false)\n",
      " |-- created_by_key: integer (nullable = true)\n",
      " |-- approved_by_key: integer (nullable = true)\n",
      " |-- submitted_by_key: integer (nullable = true)\n",
      " |-- creation_date_key: integer (nullable = true)\n",
      " |-- approved_date_key: integer (nullable = true)\n",
      " |-- submitted_date_key: integer (nullable = true)\n",
      " |-- date_received_key: integer (nullable = true)\n",
      " |-- po_detail_quantity: integer (nullable = true)\n",
      " |-- po_detail_unit_cost: double (nullable = true)\n",
      " |-- product_list_price: decimal(19,4) (nullable = true)\n",
      " |-- bronze_list_price: double (nullable = true)\n",
      " |-- receipt_time: timestamp (nullable = true)\n",
      " |-- source_file: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_purchase_orders_silver.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b891abcc-4c45-4364-bd6d-30a0a7d886e6",
   "metadata": {},
   "source": [
    "##### 8.3.3. Write the Transformed Streaming data to the Data Lakehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b414de3c-ab4d-4d4f-a987-81fb417c99a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase_orders_checkpoint_silver = os.path.join(purchase_orders_output_silver, '_checkpoint')\n",
    "\n",
    "purchase_orders_silver_query = (\n",
    "    df_purchase_orders_silver.writeStream \\\n",
    "    # TODO: writeStream, in 'parquet' format, to 'purchase_orders_output_silver' in 'append' mode\n",
    "    .format(\"parquet\")\n",
    "    .outputMode(\"append\")\n",
    "    .queryName(\"purchase_orders_silver\")\n",
    "    .trigger(availableNow=True)\n",
    "    .option(\"checkpointLocation\", purchase_orders_checkpoint_silver)\n",
    "    .option(\"compression\", \"snappy\")\n",
    "    .start(purchase_orders_output_silver)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2133b8c8-59a9-4f0b-a47a-4eb5b6b64c7b",
   "metadata": {},
   "source": [
    "##### 8.3.4. Unit Test: Implement Query Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "bc6eb141-c92e-4f70-9757-0f7e93eac435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query ID: 68166eb8-82dd-4c0b-8be7-8926472e24c0\n",
      "Query Name: purchase_orders_silver\n",
      "Query Status: {'message': 'Stopped', 'isDataAvailable': False, 'isTriggerActive': False}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Query ID: {purchase_orders_silver_query.id}\")\n",
    "print(f\"Query Name: {purchase_orders_silver_query.name}\")\n",
    "print(f\"Query Status: {purchase_orders_silver_query.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "89be4f13-e58e-40dd-8286-a94c195747fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase_orders_silver_query.awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e153434-28ad-47f1-889c-d3c5ad6e9825",
   "metadata": {},
   "source": [
    "#### 8.4. Create Gold Layer: Perform Aggregations\n",
    "##### 8.4.1. Define a Query to Create a Business Report\n",
    "Create a new Gold table using the PySpark API. The table should include the Suppliers' Company Name, the Product Name, the Total Quantity, Total Unit Cost, and Total List Price for all the purchase orders placed per Supplier for each Product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "782a3b8d-7be1-457e-b2b2-0858269a886f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum as _sum\n",
    "df_fact_pos_products_per_supplier_gold = (spark.readStream.format(\"parquet\").load(purchase_orders_output_silver) \\\n",
    "# .join to the 'df_dim_products' dimension\n",
    "# .join to the 'df_dim_suppliers' dimension\n",
    "# .groupBy 'company' and 'product_name'\n",
    "# sum 'po_detail_quantity' as 'Total Quantity'\n",
    "# sum 'po_detail_unit_cost' as 'Total Unit Cost'\n",
    "# sum 'list_price' as 'Total List Price'\n",
    "# orderBy 'Total Quantity' in descending order\n",
    "        .join(df_dim_products, \"product_key\")\n",
    "        .join(df_dim_suppliers, \"supplier_key\")\n",
    "        .withWatermark(\"receipt_time\", \"10 minutes\")\n",
    "        .groupBy(\"company\", \"product_name\")\n",
    "        .agg(\n",
    "            _sum(\"po_detail_quantity\").alias(\"Total Quantity\"),\n",
    "            _sum(\"po_detail_unit_cost\").alias(\"Total Unit Cost\"),\n",
    "            _sum(\"bronze_list_price\").alias(\"Total List Price\")\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c972e0-8ac6-458f-b6ab-703348f0b887",
   "metadata": {},
   "source": [
    "##### 8.4.2. Write the Streaming data to Memory in \"Complete\" mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "3c2a4ee8-54a1-4f20-b100-0116be5c1bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase_orders_checkpoint_gold = os.path.join(purchase_orders_output_gold, \"_checkpoint\")\n",
    "\n",
    "purchase_orders_gold_query = (\n",
    "    df_fact_pos_products_per_supplier_gold.writeStream \\\n",
    "    # create the new \"fact_pos_products_per_supplier\" query\n",
    "        .format(\"memory\")\n",
    "        .outputMode(\"complete\")  # Required for sorting aggregated data later\n",
    "        .option(\"checkpointLocation\", purchase_orders_checkpoint_gold)\n",
    "        .queryName(\"fact_pos_products_per_supplier\")\n",
    "        .trigger(availableNow=True)\n",
    "        .start()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "a1fe0ce1-73ec-4233-9246-8663086fa37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The stream has processed 1 batchs\n"
     ]
    }
   ],
   "source": [
    "wait_until_stream_is_ready(purchase_orders_gold_query, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8969d4cc-85e2-4ddc-bae2-875243fbcd98",
   "metadata": {},
   "source": [
    "##### 8.4.3. Query the Gold Data from Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8f8848aa-adb0-40e6-8c68-de8b2936e350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- company: string (nullable = true)\n",
      " |-- product_name: string (nullable = true)\n",
      " |-- Total Quantity: long (nullable = true)\n",
      " |-- Total Unit Cost: double (nullable = true)\n",
      " |-- Total List Price: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fact_pos_products_per_supplier = spark.sql(\"SELECT * FROM fact_pos_products_per_supplier\")\n",
    "df_fact_pos_products_per_supplier.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5babafb4-e123-41ff-8dbc-62b29fe58dd6",
   "metadata": {},
   "source": [
    "##### 8.4.4. Create the Final Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "beb16afc-a048-44b0-b8e3-6a73d677723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fact_pos_products_per_supplier_gold_final = df_fact_pos_products_per_supplier.selectExpr(\n",
    "    \"company as Supplier\",\n",
    "    \"product_name as Product\",\n",
    "    \"`Total Quantity`\",\n",
    "    \"`Total Unit Cost`\",\n",
    "    \"`Total List Price`\"\n",
    ")\n",
    "# .select() the 'company' column as 'Supplier', the 'product_name' column as 'Product',\n",
    "# along with the 'Total Quantity', 'Total Unit Cost', and 'Total List Price' columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2a3411-c649-4036-a28f-4fdc289c5814",
   "metadata": {},
   "source": [
    "##### 8.4.5. Load the Final Results into a New Table and Display the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "45668f44-148b-418f-b956-7dbe2de36e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Supplier</th>\n",
       "      <th>Product</th>\n",
       "      <th>Total Quantity</th>\n",
       "      <th>Total Unit Cost</th>\n",
       "      <th>Total List Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Supplier H</td>\n",
       "      <td>Northwind Traders Chai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Supplier C</td>\n",
       "      <td>Northwind Traders Tomato Sauce</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Supplier B</td>\n",
       "      <td>Northwind Traders Scones</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Supplier C</td>\n",
       "      <td>Northwind Traders Cajun Seasoning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Supplier B</td>\n",
       "      <td>Northwind Traders Fruit Cocktail</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Supplier B</td>\n",
       "      <td>Northwind Traders Boysenberry Spread</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Supplier E</td>\n",
       "      <td>Northwind Traders Gnocchi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Supplier F</td>\n",
       "      <td>Northwind Traders Brownie Mix</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Supplier B</td>\n",
       "      <td>Northwind Traders Dried Apples</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Supplier B</td>\n",
       "      <td>Northwind Traders Almonds</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Supplier B</td>\n",
       "      <td>Northwind Traders Marmalade</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Supplier C</td>\n",
       "      <td>Northwind Traders Olive Oil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Supplier F</td>\n",
       "      <td>Northwind Traders Mozzarella</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Supplier B</td>\n",
       "      <td>Northwind Traders Curry Sauce</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Supplier C</td>\n",
       "      <td>Northwind Traders Hot Pepper Sauce</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Supplier H</td>\n",
       "      <td>Northwind Traders Boysenberry Spread</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Supplier A</td>\n",
       "      <td>Northwind Traders Coffee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Supplier E</td>\n",
       "      <td>Northwind Traders Ravioli</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Supplier A</td>\n",
       "      <td>Northwind Traders Beer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Supplier E</td>\n",
       "      <td>Northwind Traders Mozzarella</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Supplier A</td>\n",
       "      <td>Northwind Traders Green Tea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Supplier G</td>\n",
       "      <td>Northwind Traders Crab Meat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Supplier E</td>\n",
       "      <td>Northwind Traders Long Grain Rice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Supplier B</td>\n",
       "      <td>Northwind Traders Crab Meat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Supplier A</td>\n",
       "      <td>Northwind Traders Chai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Supplier B</td>\n",
       "      <td>Northwind Traders Dried Pears</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Supplier B</td>\n",
       "      <td>Northwind Traders Chocolate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Supplier B</td>\n",
       "      <td>Northwind Traders Walnuts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Supplier B</td>\n",
       "      <td>Northwind Traders Chocolate Biscuits Mix</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Supplier C</td>\n",
       "      <td>Northwind Traders Syrup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Supplier B</td>\n",
       "      <td>Northwind Traders Clam Chowder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Supplier D</td>\n",
       "      <td>Northwind Traders Dried Plums</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Supplier B</td>\n",
       "      <td>Northwind Traders Mustard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Supplier                                   Product  Total Quantity  \\\n",
       "0   Supplier H                    Northwind Traders Chai             NaN   \n",
       "1   Supplier C            Northwind Traders Tomato Sauce             NaN   \n",
       "2   Supplier B                  Northwind Traders Scones             NaN   \n",
       "3   Supplier C         Northwind Traders Cajun Seasoning             NaN   \n",
       "4   Supplier B          Northwind Traders Fruit Cocktail             NaN   \n",
       "5   Supplier B      Northwind Traders Boysenberry Spread             NaN   \n",
       "6   Supplier E                 Northwind Traders Gnocchi             NaN   \n",
       "7   Supplier F             Northwind Traders Brownie Mix             NaN   \n",
       "8   Supplier B            Northwind Traders Dried Apples             NaN   \n",
       "9   Supplier B                 Northwind Traders Almonds             NaN   \n",
       "10  Supplier B               Northwind Traders Marmalade             NaN   \n",
       "11  Supplier C               Northwind Traders Olive Oil             NaN   \n",
       "12  Supplier F              Northwind Traders Mozzarella             NaN   \n",
       "13  Supplier B             Northwind Traders Curry Sauce             NaN   \n",
       "14  Supplier C        Northwind Traders Hot Pepper Sauce             NaN   \n",
       "15  Supplier H      Northwind Traders Boysenberry Spread             NaN   \n",
       "16  Supplier A                  Northwind Traders Coffee             NaN   \n",
       "17  Supplier E                 Northwind Traders Ravioli             NaN   \n",
       "18  Supplier A                    Northwind Traders Beer             NaN   \n",
       "19  Supplier E              Northwind Traders Mozzarella             NaN   \n",
       "20  Supplier A               Northwind Traders Green Tea             NaN   \n",
       "21  Supplier G               Northwind Traders Crab Meat             NaN   \n",
       "22  Supplier E         Northwind Traders Long Grain Rice             NaN   \n",
       "23  Supplier B               Northwind Traders Crab Meat             NaN   \n",
       "24  Supplier A                    Northwind Traders Chai             NaN   \n",
       "25  Supplier B             Northwind Traders Dried Pears             NaN   \n",
       "26  Supplier B               Northwind Traders Chocolate             NaN   \n",
       "27  Supplier B                 Northwind Traders Walnuts             NaN   \n",
       "28  Supplier B  Northwind Traders Chocolate Biscuits Mix             NaN   \n",
       "29  Supplier C                   Northwind Traders Syrup             NaN   \n",
       "30  Supplier B            Northwind Traders Clam Chowder             NaN   \n",
       "31  Supplier D             Northwind Traders Dried Plums             NaN   \n",
       "32  Supplier B                 Northwind Traders Mustard             NaN   \n",
       "\n",
       "    Total Unit Cost  Total List Price  \n",
       "0               NaN               NaN  \n",
       "1               NaN               NaN  \n",
       "2               NaN               NaN  \n",
       "3               NaN               NaN  \n",
       "4               NaN               NaN  \n",
       "5               NaN               NaN  \n",
       "6               NaN               NaN  \n",
       "7               NaN               NaN  \n",
       "8               NaN               NaN  \n",
       "9               NaN               NaN  \n",
       "10              NaN               NaN  \n",
       "11              NaN               NaN  \n",
       "12              NaN               NaN  \n",
       "13              NaN               NaN  \n",
       "14              NaN               NaN  \n",
       "15              NaN               NaN  \n",
       "16              NaN               NaN  \n",
       "17              NaN               NaN  \n",
       "18              NaN               NaN  \n",
       "19              NaN               NaN  \n",
       "20              NaN               NaN  \n",
       "21              NaN               NaN  \n",
       "22              NaN               NaN  \n",
       "23              NaN               NaN  \n",
       "24              NaN               NaN  \n",
       "25              NaN               NaN  \n",
       "26              NaN               NaN  \n",
       "27              NaN               NaN  \n",
       "28              NaN               NaN  \n",
       "29              NaN               NaN  \n",
       "30              NaN               NaN  \n",
       "31              NaN               NaN  \n",
       "32              NaN               NaN  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fact_pos_products_per_supplier_gold_final.write.saveAsTable(f\"{dest_database}.fact_pos_products_per_supplier\", mode=\"overwrite\")\n",
    "spark.sql(f\"SELECT * FROM {dest_database}.fact_pos_products_per_supplier\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efd14eb-1c30-4d29-b5ca-46dadafa5419",
   "metadata": {},
   "source": [
    "### 9.0. Stop the Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "c6edcbef-aa54-4ca0-aa9f-2b58c8931537",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
